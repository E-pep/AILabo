{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practice Session AI: Data Science"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "run_control": {
     "marked": false
    },
    "tags": [
     "locked"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naam: Leroy\n",
      "Voornaam: Paul Albert\n",
      "S-nummer: r0581264\n",
      "Richting: E-ICT\n"
     ]
    }
   ],
   "source": [
    "# vul in\n",
    "\n",
    "print(\"Naam:\", \"Leroy\")\n",
    "print(\"Voornaam:\", \"Paul Albert\")\n",
    "print(\"S-nummer:\", \"r0581264\")\n",
    "print(\"Richting:\", \"E-ICT\")\n",
    "\n",
    "# druk <ctrl> + <enter>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welkom bij de eerste labosessie van Artificiële Intelligentie! In deze sessie maken we kennis met enkele belangrijke concepten uit de *Data Science*, het onderzoeksveld dat de kracht van statistiek, algebra en computerwetenschappen combineert en deze afvuurt op data. In de laatste 10-15 jaar heeft deze branche enorm aan belang gewonnen door de exponentieel stijgende groei van het internet, de dalende prijs van opslagruimte en de opkomende wensen van de bedrijfswereld om *Big Data* te gebruiken als leiddraad voor belangrijke beslissingen.\n",
    "\n",
    "Dit document is een zogenaamde ``IPython Notebook``. Een notebook bevat een mix van pure tekst en uitvoerbare code, en is uitermate geschikt om op een esthetisch verantwoorde manier rekenresultaten numerisch en grafisch voor te stellen. De code in de blokken kan uitgevoerd worden met het toetsencommando ``<control> + <enter>`` of ``<shift> + <enter>``. Als er iets misgelopen is (bvb. datacorruptie, variabele overschreven, ...) kan de notebook opnieuw opgestart en uitgevoerd worden door op &#9193; te klikken.\n",
    "\n",
    "Sommige codeblokken zijn op voorhand al ingevuld, maar de meeste zijn nog leeg. De bedoeling is dat we deze in dit labo gaan invullen op basis van de opdracht in het voorgaande groene tekstblok. **Let op:** soms wordt er niet enkel gevraagd naar code, maar ook naar wat tekstuele uitleg. Vergeet deze vragen niet te op te lossen! Deze antwoorden mogen gewoon toegevoegd worden aan het codeblok m.b.v. een ``print()``.\n",
    "\n",
    "In de notebook komen een aantal libraries aan bod die geen deel uitmaken van de *Python standard library* en zijn dus misschien vrij onbekend. In de tekst staan vaak verwijzingen naar de online documentatie van deze libraries, en het is ten sterkste aanbevolen om deze dan ook te gebruiken.\n",
    "\n",
    "Veel succes!\n",
    "\n",
    "## Data Acquisition\n",
    "\n",
    "De eerste stap in het proces bestaat uiteraard uit het verzamelen van gegevens die onderzocht kunnen worden. De wijzes waarop dit kan gebeuren zijn zeer divers en afhankelijk van de use case. Enkele voorbeelden:\n",
    "\n",
    "* database queries (SQL) op vooraf verzamelde grote databestanden\n",
    "* uitlezen van analoge of digitale sensorwaarden\n",
    "* informatie van websites halen via web scraping of API querying\n",
    "* resultaten van labo-experimenten manueel omzetten naar tabelformaat (vb. Excel)\n",
    "* ...\n",
    "\n",
    "In dit labo houden we ons met deze stap niet bezig en wordt er een kant en klare [dataset](https://archive.ics.uci.edu/ml/datasets/wine) in CSV-formaat ter beschikking gesteld. Deze bevat een reeks chemische en fysische gegevens over wijnen gemaakt van drie verschillende druivensoorten (ook wel *cultivars* genoemd). De namen van deze eigenschappen zijn bekend, de eenheden waarin ze uitgedrukt zijn niet. \n",
    "\n",
    "Bij de kolommen van de tabel kan er een onderscheid gemaakt worden tussen *features* (soms ook wel \"onafhankelijke variabelen\" genoemd) en *target* (\"afhankelijke variabele\"). De eigenschappen die in de *feature*-kolommen staan zullen worden gebruikt om een voorspelling te doen over de aard van de *target*.\n",
    "\n",
    "### Loading Imports\n",
    "Voordat we beginnen, importeren we enkele packages waarmee we gaan werken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "locked"
    ]
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "\n",
    "# numerical tools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# plotting tools\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import graphviz\n",
    "\n",
    "# machine learning tools\n",
    "import sklearn\n",
    "import pandas_ml as pdml\n",
    "\n",
    "# notebook initialisation\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **NumPy**: Library voor (vooral algebraïsche) wiskundige berekeningen. Zeer efficiënt in het uitvoeren van vectoriële bewerkingen.\n",
    "* **Pandas**: Package om tabulaire data voor te stellen in de vorm van een ``DataFrame`` of een ``Series``.\n",
    "* **MatPlotLib**: Plotting toolkit voor Python, API is sterk gebaseerd op die van MATLAB.\n",
    "* **Seaborn**: Uitbreiding op MatPlotLib.\n",
    "* **GraphViz**: Toolkit om grafen en boomvormige datastructuren te tekenen.\n",
    "* **Scikit-Learn**: *All-inclusive* machine learning library voor Python. Zeer uitgebreid: bevat het merendeel van de courante classificatie-, regressie- en clusteralgoritmes (met uitzondering van boosted trees en DNNs).\n",
    "* **Pandas-ML**: Wrapper om Pandas en Scikit-Learn te linken."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Dataset\n",
    "\n",
    "[**Pandas**](https://pandas.pydata.org/pandas-docs/stable/10min.html) (``pd``) is de bibliotheek waarmee we de data gaan voorstellen. Het basisobject van deze package is de ``Series``, een kolom van datapunten die allemaal hetzelfde type (``dtype``) hebben, zoals ``int``, ``float`` en ``object`` (meestal strings). Wanneer meerdere van deze ``Series`` samen gegroepeerd worden, spreken we van een ``DataFrame``.\n",
    "\n",
    "Het inlezen van de dataset kan best gedaan worden met de ``pd.read_csv()`` functie, die een ``DataFrame`` teruggeeft; lees de online documentatie voor meer info. \n",
    "\n",
    "De namen die bij de kolommen horen zijn als volgt: \n",
    "``'type', 'alcohol', 'malic_acid', 'ash', 'alkalinity', 'magnesium', 'total_phenols', 'flavonoids', 'nonflavonoid_phenols', 'proanthocyanins', 'color_intensity', 'color_hue', 'OD280/OD315', 'proline'``."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "Lees de data uit het bestand ``data/wine.csv`` in in een ``DataFrame``, en geef de kolommen de juiste namen. Noem deze variabele ``df``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = ['type', 'alcohol', 'malic_acid', 'ash', 'alkalinity', 'magnesium', 'total_phenols', 'flavonoids', 'nonflavonoid_phenols', 'proanthocyanins', 'color_intensity', 'color_hue', 'OD280/OD315', 'proline']\n",
    "df = pd.read_csv(\"data/wine.csv\", names=col_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "Controleer of het verkegen dataframe op een juiste manier werd ingeladen met de ``DataFrame.head()`` methode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alkalinity</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavonoids</th>\n",
       "      <th>nonflavonoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>color_hue</th>\n",
       "      <th>OD280/OD315</th>\n",
       "      <th>proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type  alcohol  malic_acid   ash  alkalinity  magnesium  total_phenols  \\\n",
       "0     1    14.23        1.71  2.43        15.6        127           2.80   \n",
       "1     1    13.20        1.78  2.14        11.2        100           2.65   \n",
       "2     1    13.16        2.36  2.67        18.6        101           2.80   \n",
       "3     1    14.37        1.95  2.50        16.8        113           3.85   \n",
       "4     1    13.24        2.59  2.87        21.0        118           2.80   \n",
       "\n",
       "   flavonoids  nonflavonoid_phenols  proanthocyanins  color_intensity  \\\n",
       "0        3.06                  0.28             2.29             5.64   \n",
       "1        2.76                  0.26             1.28             4.38   \n",
       "2        3.24                  0.30             2.81             5.68   \n",
       "3        3.49                  0.24             2.18             7.80   \n",
       "4        2.69                  0.39             1.82             4.32   \n",
       "\n",
       "   color_hue  OD280/OD315  proline  \n",
       "0       1.04         3.92     1065  \n",
       "1       1.05         3.40     1050  \n",
       "2       1.03         3.17     1185  \n",
       "3       0.86         3.45     1480  \n",
       "4       1.04         2.93      735  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "In de dagelijkse wereld is het vrij zeldzaam dat de verzamelde data *out of the box* gebruikt kan worden in modelleringssystemen. Vaak zijn er waarden die gewoonweg ontbreken in één of meerdere kolommen, is de schaling van de waarden per kolom niet optimaal, of is de data in hun huidige vorm gewoonweg niet interpreteerbaar door de algoritmes. We zullen nu een aantal stappen doorlopen waarmee deze problemen verholpen kunnen worden.\n",
    "\n",
    "### Label Encoding\n",
    "\n",
    "De namen van de wijnrassen zijn voor mensen eenvoudig te begrijpen, maar voor computeralgoritmes ligt dat moeilijker. Om dit probleem te verhelpen, encoderen we de de `type` kolom naar een reeks *ordinale* waarden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "Vervang elke naam door een getal, beginnend vanaf 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['type'] == 'Trebbiano', 'type'] = 1\n",
    "df.loc[df['type'] == 'Montepulciano', 'type'] = 2\n",
    "df.loc[df['type'] == 'Chardonnay', 'type'] = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Missing Values\n",
    "\n",
    "Datasets zijn zelden volmaakt. Het gebeurt vaker dan gewenst dat bij een *data entry* één of meerdere waarden ontbreken, bvb. door datacorruptie. [Dit hoofdstuk](https://pandas.pydata.org/pandas-docs/stable/missing_data.html) uit de Pandas-documentatie beschrijft uitvoerig hoe hiermee omgegegaan kan worden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "Vind de rijen die minstens 1 *empty value* hebben en verwijder deze uit de dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.isnull().any(axis=1)]\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling\n",
    "\n",
    "Features waarvan waarden een andere grootteorde hebben dan de rest van de dataset hebben in veel machine learning algoritmes een te grote invloed op de voorspellingen. Daarom worden ze vaak herschaald opdat ze allemaal rond dezelfde gemiddelde waarde komen te liggen (meestal 0) en een standaarddeviatie van 1 krijgen.\n",
    "\n",
    "Voor deze dataset gaan we in eerste instantie enkel de ``magnesium``- en ``proline``-kolommen herschalen, aangezien de maximumwaarde hiervan veel hoger liggen dan alle andere waarden in de dataset en zo een overzichtelijke visualisatie moeilijk maken. In hoodfstuk 1.5 gaan we een robuustere schaling doorvoeren op de gehele set; daarom slaan we de originele twee features even op zodat we makkelijk de oorspronkelijke staat kunnen herstellen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": [
     "locked"
    ]
   },
   "outputs": [],
   "source": [
    "df_magnesium_orig = df['magnesium'].copy()\n",
    "df_proline_orig = df['proline'].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "Herschaal de ``magnesium`` en ``proline``-features zodat de maximumwaarden hiervan onder 30 komen te liggen. Gebruik de volgende formule voor normalisatie met zelfgekozen maximumwaarde ``C``:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\mathbf{z} = \\frac{\\mathbf{x} - \\min(\\mathbf{x})}{\\max(\\mathbf{x}) - \\min(\\mathbf{x})} * C\n",
    "\\end{equation*}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alkalinity</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavonoids</th>\n",
       "      <th>nonflavonoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>color_hue</th>\n",
       "      <th>OD280/OD315</th>\n",
       "      <th>proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>18.586957</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>16.840228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>9.782609</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>16.519258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>10.108696</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>19.407989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>14.021739</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>25.720399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>15.652174</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>9.778887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>14.20</td>\n",
       "      <td>1.76</td>\n",
       "      <td>2.45</td>\n",
       "      <td>15.2</td>\n",
       "      <td>13.695652</td>\n",
       "      <td>3.27</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.97</td>\n",
       "      <td>6.75</td>\n",
       "      <td>1.05</td>\n",
       "      <td>2.85</td>\n",
       "      <td>25.078459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>14.39</td>\n",
       "      <td>1.87</td>\n",
       "      <td>2.45</td>\n",
       "      <td>14.6</td>\n",
       "      <td>8.478261</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2.52</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.98</td>\n",
       "      <td>5.25</td>\n",
       "      <td>1.02</td>\n",
       "      <td>3.58</td>\n",
       "      <td>21.654779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>14.06</td>\n",
       "      <td>2.15</td>\n",
       "      <td>2.61</td>\n",
       "      <td>17.6</td>\n",
       "      <td>16.630435</td>\n",
       "      <td>2.60</td>\n",
       "      <td>2.51</td>\n",
       "      <td>0.31</td>\n",
       "      <td>1.25</td>\n",
       "      <td>5.05</td>\n",
       "      <td>1.06</td>\n",
       "      <td>3.58</td>\n",
       "      <td>21.761769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>14.83</td>\n",
       "      <td>1.64</td>\n",
       "      <td>2.17</td>\n",
       "      <td>14.0</td>\n",
       "      <td>8.804348</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.98</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.98</td>\n",
       "      <td>5.20</td>\n",
       "      <td>1.08</td>\n",
       "      <td>2.85</td>\n",
       "      <td>16.412268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>13.86</td>\n",
       "      <td>1.35</td>\n",
       "      <td>2.27</td>\n",
       "      <td>16.0</td>\n",
       "      <td>9.130435</td>\n",
       "      <td>2.98</td>\n",
       "      <td>3.15</td>\n",
       "      <td>0.22</td>\n",
       "      <td>1.85</td>\n",
       "      <td>7.22</td>\n",
       "      <td>1.01</td>\n",
       "      <td>3.55</td>\n",
       "      <td>16.412268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>14.10</td>\n",
       "      <td>2.16</td>\n",
       "      <td>2.30</td>\n",
       "      <td>18.0</td>\n",
       "      <td>11.413043</td>\n",
       "      <td>2.95</td>\n",
       "      <td>3.32</td>\n",
       "      <td>0.22</td>\n",
       "      <td>2.38</td>\n",
       "      <td>5.75</td>\n",
       "      <td>1.25</td>\n",
       "      <td>3.17</td>\n",
       "      <td>26.362340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>14.12</td>\n",
       "      <td>1.48</td>\n",
       "      <td>2.32</td>\n",
       "      <td>16.8</td>\n",
       "      <td>8.152174</td>\n",
       "      <td>2.20</td>\n",
       "      <td>2.43</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.57</td>\n",
       "      <td>5.00</td>\n",
       "      <td>1.17</td>\n",
       "      <td>2.82</td>\n",
       "      <td>21.440799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>13.75</td>\n",
       "      <td>1.73</td>\n",
       "      <td>2.41</td>\n",
       "      <td>16.0</td>\n",
       "      <td>6.195652</td>\n",
       "      <td>2.60</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.81</td>\n",
       "      <td>5.60</td>\n",
       "      <td>1.15</td>\n",
       "      <td>2.90</td>\n",
       "      <td>22.296719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>14.75</td>\n",
       "      <td>1.73</td>\n",
       "      <td>2.39</td>\n",
       "      <td>11.4</td>\n",
       "      <td>6.847826</td>\n",
       "      <td>3.10</td>\n",
       "      <td>3.69</td>\n",
       "      <td>0.43</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.40</td>\n",
       "      <td>1.25</td>\n",
       "      <td>2.73</td>\n",
       "      <td>18.659058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>14.38</td>\n",
       "      <td>1.87</td>\n",
       "      <td>2.38</td>\n",
       "      <td>12.0</td>\n",
       "      <td>10.434783</td>\n",
       "      <td>3.30</td>\n",
       "      <td>3.64</td>\n",
       "      <td>0.29</td>\n",
       "      <td>2.96</td>\n",
       "      <td>7.50</td>\n",
       "      <td>1.20</td>\n",
       "      <td>3.00</td>\n",
       "      <td>27.154066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>13.63</td>\n",
       "      <td>1.81</td>\n",
       "      <td>2.70</td>\n",
       "      <td>17.2</td>\n",
       "      <td>13.695652</td>\n",
       "      <td>2.85</td>\n",
       "      <td>2.91</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.46</td>\n",
       "      <td>7.30</td>\n",
       "      <td>1.28</td>\n",
       "      <td>2.88</td>\n",
       "      <td>22.082739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>14.30</td>\n",
       "      <td>1.92</td>\n",
       "      <td>2.72</td>\n",
       "      <td>20.0</td>\n",
       "      <td>16.304348</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.14</td>\n",
       "      <td>0.33</td>\n",
       "      <td>1.97</td>\n",
       "      <td>6.20</td>\n",
       "      <td>1.07</td>\n",
       "      <td>2.65</td>\n",
       "      <td>21.440799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>13.83</td>\n",
       "      <td>1.57</td>\n",
       "      <td>2.62</td>\n",
       "      <td>20.0</td>\n",
       "      <td>14.673913</td>\n",
       "      <td>2.95</td>\n",
       "      <td>3.40</td>\n",
       "      <td>0.40</td>\n",
       "      <td>1.72</td>\n",
       "      <td>6.60</td>\n",
       "      <td>1.13</td>\n",
       "      <td>2.57</td>\n",
       "      <td>18.231098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>14.19</td>\n",
       "      <td>1.59</td>\n",
       "      <td>2.48</td>\n",
       "      <td>16.5</td>\n",
       "      <td>12.391304</td>\n",
       "      <td>3.30</td>\n",
       "      <td>3.93</td>\n",
       "      <td>0.32</td>\n",
       "      <td>1.86</td>\n",
       "      <td>8.70</td>\n",
       "      <td>1.23</td>\n",
       "      <td>2.82</td>\n",
       "      <td>30.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>13.64</td>\n",
       "      <td>3.10</td>\n",
       "      <td>2.56</td>\n",
       "      <td>15.2</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>2.70</td>\n",
       "      <td>3.03</td>\n",
       "      <td>0.17</td>\n",
       "      <td>1.66</td>\n",
       "      <td>5.10</td>\n",
       "      <td>0.96</td>\n",
       "      <td>3.36</td>\n",
       "      <td>12.132668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>14.06</td>\n",
       "      <td>1.63</td>\n",
       "      <td>2.28</td>\n",
       "      <td>16.0</td>\n",
       "      <td>18.260870</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.17</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.10</td>\n",
       "      <td>5.65</td>\n",
       "      <td>1.09</td>\n",
       "      <td>3.71</td>\n",
       "      <td>10.741797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>12.93</td>\n",
       "      <td>3.80</td>\n",
       "      <td>2.65</td>\n",
       "      <td>18.6</td>\n",
       "      <td>10.434783</td>\n",
       "      <td>2.41</td>\n",
       "      <td>2.41</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.98</td>\n",
       "      <td>4.50</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.52</td>\n",
       "      <td>10.527817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>13.71</td>\n",
       "      <td>1.86</td>\n",
       "      <td>2.36</td>\n",
       "      <td>16.6</td>\n",
       "      <td>10.108696</td>\n",
       "      <td>2.61</td>\n",
       "      <td>2.88</td>\n",
       "      <td>0.27</td>\n",
       "      <td>1.69</td>\n",
       "      <td>3.80</td>\n",
       "      <td>1.11</td>\n",
       "      <td>4.00</td>\n",
       "      <td>16.198288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>12.85</td>\n",
       "      <td>1.60</td>\n",
       "      <td>2.52</td>\n",
       "      <td>17.8</td>\n",
       "      <td>8.152174</td>\n",
       "      <td>2.48</td>\n",
       "      <td>2.37</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.46</td>\n",
       "      <td>3.93</td>\n",
       "      <td>1.09</td>\n",
       "      <td>3.63</td>\n",
       "      <td>15.770328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>13.50</td>\n",
       "      <td>1.81</td>\n",
       "      <td>2.61</td>\n",
       "      <td>20.0</td>\n",
       "      <td>8.478261</td>\n",
       "      <td>2.53</td>\n",
       "      <td>2.61</td>\n",
       "      <td>0.28</td>\n",
       "      <td>1.66</td>\n",
       "      <td>3.52</td>\n",
       "      <td>1.12</td>\n",
       "      <td>3.82</td>\n",
       "      <td>12.132668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>13.05</td>\n",
       "      <td>2.05</td>\n",
       "      <td>3.22</td>\n",
       "      <td>25.0</td>\n",
       "      <td>17.608696</td>\n",
       "      <td>2.63</td>\n",
       "      <td>2.68</td>\n",
       "      <td>0.47</td>\n",
       "      <td>1.92</td>\n",
       "      <td>3.58</td>\n",
       "      <td>1.13</td>\n",
       "      <td>3.20</td>\n",
       "      <td>11.811698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>13.39</td>\n",
       "      <td>1.77</td>\n",
       "      <td>2.62</td>\n",
       "      <td>16.1</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>2.85</td>\n",
       "      <td>2.94</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.45</td>\n",
       "      <td>4.80</td>\n",
       "      <td>0.92</td>\n",
       "      <td>3.22</td>\n",
       "      <td>19.621969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>13.30</td>\n",
       "      <td>1.72</td>\n",
       "      <td>2.14</td>\n",
       "      <td>17.0</td>\n",
       "      <td>7.826087</td>\n",
       "      <td>2.40</td>\n",
       "      <td>2.19</td>\n",
       "      <td>0.27</td>\n",
       "      <td>1.35</td>\n",
       "      <td>3.95</td>\n",
       "      <td>1.02</td>\n",
       "      <td>2.77</td>\n",
       "      <td>21.547789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>13.87</td>\n",
       "      <td>1.90</td>\n",
       "      <td>2.80</td>\n",
       "      <td>19.4</td>\n",
       "      <td>12.065217</td>\n",
       "      <td>2.95</td>\n",
       "      <td>2.97</td>\n",
       "      <td>0.37</td>\n",
       "      <td>1.76</td>\n",
       "      <td>4.50</td>\n",
       "      <td>1.25</td>\n",
       "      <td>3.40</td>\n",
       "      <td>13.630528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>14.02</td>\n",
       "      <td>1.68</td>\n",
       "      <td>2.21</td>\n",
       "      <td>16.0</td>\n",
       "      <td>8.478261</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.33</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.98</td>\n",
       "      <td>4.70</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.59</td>\n",
       "      <td>16.198288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>2</td>\n",
       "      <td>13.32</td>\n",
       "      <td>3.24</td>\n",
       "      <td>2.38</td>\n",
       "      <td>21.5</td>\n",
       "      <td>7.173913</td>\n",
       "      <td>1.93</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.45</td>\n",
       "      <td>1.25</td>\n",
       "      <td>8.42</td>\n",
       "      <td>0.55</td>\n",
       "      <td>1.62</td>\n",
       "      <td>7.960057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>2</td>\n",
       "      <td>13.08</td>\n",
       "      <td>3.90</td>\n",
       "      <td>2.36</td>\n",
       "      <td>21.5</td>\n",
       "      <td>14.021739</td>\n",
       "      <td>1.41</td>\n",
       "      <td>1.39</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.14</td>\n",
       "      <td>9.40</td>\n",
       "      <td>0.57</td>\n",
       "      <td>1.33</td>\n",
       "      <td>5.820257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>2</td>\n",
       "      <td>13.50</td>\n",
       "      <td>3.12</td>\n",
       "      <td>2.62</td>\n",
       "      <td>24.0</td>\n",
       "      <td>17.282609</td>\n",
       "      <td>1.40</td>\n",
       "      <td>1.57</td>\n",
       "      <td>0.22</td>\n",
       "      <td>1.25</td>\n",
       "      <td>8.60</td>\n",
       "      <td>0.59</td>\n",
       "      <td>1.30</td>\n",
       "      <td>4.750357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>2</td>\n",
       "      <td>12.79</td>\n",
       "      <td>2.67</td>\n",
       "      <td>2.48</td>\n",
       "      <td>22.0</td>\n",
       "      <td>13.695652</td>\n",
       "      <td>1.48</td>\n",
       "      <td>1.36</td>\n",
       "      <td>0.24</td>\n",
       "      <td>1.26</td>\n",
       "      <td>10.80</td>\n",
       "      <td>0.48</td>\n",
       "      <td>1.47</td>\n",
       "      <td>4.322397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>2</td>\n",
       "      <td>13.11</td>\n",
       "      <td>1.90</td>\n",
       "      <td>2.75</td>\n",
       "      <td>25.5</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>2.20</td>\n",
       "      <td>1.28</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.56</td>\n",
       "      <td>7.10</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1.33</td>\n",
       "      <td>3.145506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>2</td>\n",
       "      <td>13.23</td>\n",
       "      <td>3.30</td>\n",
       "      <td>2.28</td>\n",
       "      <td>18.5</td>\n",
       "      <td>9.130435</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1.87</td>\n",
       "      <td>10.52</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.51</td>\n",
       "      <td>8.495007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>2</td>\n",
       "      <td>12.58</td>\n",
       "      <td>1.29</td>\n",
       "      <td>2.10</td>\n",
       "      <td>20.0</td>\n",
       "      <td>10.760870</td>\n",
       "      <td>1.48</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1.40</td>\n",
       "      <td>7.60</td>\n",
       "      <td>0.58</td>\n",
       "      <td>1.55</td>\n",
       "      <td>7.746077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>2</td>\n",
       "      <td>13.17</td>\n",
       "      <td>5.19</td>\n",
       "      <td>2.32</td>\n",
       "      <td>22.0</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>1.74</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1.55</td>\n",
       "      <td>7.90</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.48</td>\n",
       "      <td>9.564907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>2</td>\n",
       "      <td>13.84</td>\n",
       "      <td>4.12</td>\n",
       "      <td>2.38</td>\n",
       "      <td>19.5</td>\n",
       "      <td>6.195652</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.48</td>\n",
       "      <td>1.56</td>\n",
       "      <td>9.01</td>\n",
       "      <td>0.57</td>\n",
       "      <td>1.64</td>\n",
       "      <td>4.322397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>2</td>\n",
       "      <td>12.45</td>\n",
       "      <td>3.03</td>\n",
       "      <td>2.64</td>\n",
       "      <td>27.0</td>\n",
       "      <td>8.804348</td>\n",
       "      <td>1.90</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.63</td>\n",
       "      <td>1.14</td>\n",
       "      <td>7.50</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1.73</td>\n",
       "      <td>12.881598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>2</td>\n",
       "      <td>14.34</td>\n",
       "      <td>1.68</td>\n",
       "      <td>2.70</td>\n",
       "      <td>25.0</td>\n",
       "      <td>9.130435</td>\n",
       "      <td>2.80</td>\n",
       "      <td>1.31</td>\n",
       "      <td>0.53</td>\n",
       "      <td>2.70</td>\n",
       "      <td>13.00</td>\n",
       "      <td>0.57</td>\n",
       "      <td>1.96</td>\n",
       "      <td>8.174037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>2</td>\n",
       "      <td>13.48</td>\n",
       "      <td>1.67</td>\n",
       "      <td>2.64</td>\n",
       "      <td>22.5</td>\n",
       "      <td>6.195652</td>\n",
       "      <td>2.60</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.52</td>\n",
       "      <td>2.29</td>\n",
       "      <td>11.75</td>\n",
       "      <td>0.57</td>\n",
       "      <td>1.78</td>\n",
       "      <td>7.318117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>2</td>\n",
       "      <td>12.36</td>\n",
       "      <td>3.83</td>\n",
       "      <td>2.38</td>\n",
       "      <td>21.0</td>\n",
       "      <td>5.869565</td>\n",
       "      <td>2.30</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.04</td>\n",
       "      <td>7.65</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.58</td>\n",
       "      <td>5.178317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>2</td>\n",
       "      <td>13.69</td>\n",
       "      <td>3.26</td>\n",
       "      <td>2.54</td>\n",
       "      <td>20.0</td>\n",
       "      <td>12.065217</td>\n",
       "      <td>1.83</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.80</td>\n",
       "      <td>5.88</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1.82</td>\n",
       "      <td>8.601997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>2</td>\n",
       "      <td>12.85</td>\n",
       "      <td>3.27</td>\n",
       "      <td>2.58</td>\n",
       "      <td>22.0</td>\n",
       "      <td>11.739130</td>\n",
       "      <td>1.65</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.96</td>\n",
       "      <td>5.58</td>\n",
       "      <td>0.87</td>\n",
       "      <td>2.11</td>\n",
       "      <td>6.248217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>2</td>\n",
       "      <td>12.96</td>\n",
       "      <td>3.45</td>\n",
       "      <td>2.35</td>\n",
       "      <td>18.5</td>\n",
       "      <td>11.739130</td>\n",
       "      <td>1.39</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.94</td>\n",
       "      <td>5.28</td>\n",
       "      <td>0.68</td>\n",
       "      <td>1.75</td>\n",
       "      <td>8.495007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>2</td>\n",
       "      <td>13.78</td>\n",
       "      <td>2.76</td>\n",
       "      <td>2.30</td>\n",
       "      <td>22.0</td>\n",
       "      <td>6.521739</td>\n",
       "      <td>1.35</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.41</td>\n",
       "      <td>1.03</td>\n",
       "      <td>9.58</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.68</td>\n",
       "      <td>7.211127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>2</td>\n",
       "      <td>13.73</td>\n",
       "      <td>4.36</td>\n",
       "      <td>2.26</td>\n",
       "      <td>22.5</td>\n",
       "      <td>5.869565</td>\n",
       "      <td>1.28</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.52</td>\n",
       "      <td>1.15</td>\n",
       "      <td>6.62</td>\n",
       "      <td>0.78</td>\n",
       "      <td>1.75</td>\n",
       "      <td>5.178317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>2</td>\n",
       "      <td>13.45</td>\n",
       "      <td>3.70</td>\n",
       "      <td>2.60</td>\n",
       "      <td>23.0</td>\n",
       "      <td>13.369565</td>\n",
       "      <td>1.70</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.46</td>\n",
       "      <td>10.68</td>\n",
       "      <td>0.85</td>\n",
       "      <td>1.56</td>\n",
       "      <td>8.922967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>2</td>\n",
       "      <td>12.82</td>\n",
       "      <td>3.37</td>\n",
       "      <td>2.30</td>\n",
       "      <td>19.5</td>\n",
       "      <td>5.869565</td>\n",
       "      <td>1.48</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.97</td>\n",
       "      <td>10.26</td>\n",
       "      <td>0.72</td>\n",
       "      <td>1.75</td>\n",
       "      <td>8.708987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>2</td>\n",
       "      <td>13.58</td>\n",
       "      <td>2.58</td>\n",
       "      <td>2.69</td>\n",
       "      <td>24.5</td>\n",
       "      <td>11.413043</td>\n",
       "      <td>1.55</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.54</td>\n",
       "      <td>8.66</td>\n",
       "      <td>0.74</td>\n",
       "      <td>1.80</td>\n",
       "      <td>10.099857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>2</td>\n",
       "      <td>13.40</td>\n",
       "      <td>4.60</td>\n",
       "      <td>2.86</td>\n",
       "      <td>25.0</td>\n",
       "      <td>13.695652</td>\n",
       "      <td>1.98</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.27</td>\n",
       "      <td>1.11</td>\n",
       "      <td>8.50</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1.92</td>\n",
       "      <td>7.532097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>2</td>\n",
       "      <td>12.20</td>\n",
       "      <td>3.03</td>\n",
       "      <td>2.32</td>\n",
       "      <td>19.0</td>\n",
       "      <td>8.478261</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.73</td>\n",
       "      <td>5.50</td>\n",
       "      <td>0.66</td>\n",
       "      <td>1.83</td>\n",
       "      <td>4.964337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>2</td>\n",
       "      <td>12.77</td>\n",
       "      <td>2.39</td>\n",
       "      <td>2.28</td>\n",
       "      <td>19.5</td>\n",
       "      <td>5.217391</td>\n",
       "      <td>1.39</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.64</td>\n",
       "      <td>9.90</td>\n",
       "      <td>0.57</td>\n",
       "      <td>1.63</td>\n",
       "      <td>4.108417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>2</td>\n",
       "      <td>14.16</td>\n",
       "      <td>2.51</td>\n",
       "      <td>2.48</td>\n",
       "      <td>20.0</td>\n",
       "      <td>6.847826</td>\n",
       "      <td>1.68</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.44</td>\n",
       "      <td>1.24</td>\n",
       "      <td>9.70</td>\n",
       "      <td>0.62</td>\n",
       "      <td>1.71</td>\n",
       "      <td>8.174037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>2</td>\n",
       "      <td>13.71</td>\n",
       "      <td>5.65</td>\n",
       "      <td>2.45</td>\n",
       "      <td>20.5</td>\n",
       "      <td>8.152174</td>\n",
       "      <td>1.68</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.52</td>\n",
       "      <td>1.06</td>\n",
       "      <td>7.70</td>\n",
       "      <td>0.64</td>\n",
       "      <td>1.74</td>\n",
       "      <td>9.885877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>2</td>\n",
       "      <td>13.40</td>\n",
       "      <td>3.91</td>\n",
       "      <td>2.48</td>\n",
       "      <td>23.0</td>\n",
       "      <td>10.434783</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.41</td>\n",
       "      <td>7.30</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.56</td>\n",
       "      <td>10.099857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>2</td>\n",
       "      <td>13.27</td>\n",
       "      <td>4.28</td>\n",
       "      <td>2.26</td>\n",
       "      <td>20.0</td>\n",
       "      <td>16.304348</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.35</td>\n",
       "      <td>10.20</td>\n",
       "      <td>0.59</td>\n",
       "      <td>1.56</td>\n",
       "      <td>11.918688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>2</td>\n",
       "      <td>13.17</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.37</td>\n",
       "      <td>20.0</td>\n",
       "      <td>16.304348</td>\n",
       "      <td>1.65</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1.46</td>\n",
       "      <td>9.30</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.62</td>\n",
       "      <td>12.025678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>2</td>\n",
       "      <td>14.13</td>\n",
       "      <td>4.10</td>\n",
       "      <td>2.74</td>\n",
       "      <td>24.5</td>\n",
       "      <td>8.478261</td>\n",
       "      <td>2.05</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.35</td>\n",
       "      <td>9.20</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1.60</td>\n",
       "      <td>6.034237</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>176 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     type  alcohol  malic_acid   ash  alkalinity  magnesium  total_phenols  \\\n",
       "0       1    14.23        1.71  2.43        15.6  18.586957           2.80   \n",
       "1       1    13.20        1.78  2.14        11.2   9.782609           2.65   \n",
       "2       1    13.16        2.36  2.67        18.6  10.108696           2.80   \n",
       "3       1    14.37        1.95  2.50        16.8  14.021739           3.85   \n",
       "4       1    13.24        2.59  2.87        21.0  15.652174           2.80   \n",
       "5       1    14.20        1.76  2.45        15.2  13.695652           3.27   \n",
       "6       1    14.39        1.87  2.45        14.6   8.478261           2.50   \n",
       "7       1    14.06        2.15  2.61        17.6  16.630435           2.60   \n",
       "8       1    14.83        1.64  2.17        14.0   8.804348           2.80   \n",
       "9       1    13.86        1.35  2.27        16.0   9.130435           2.98   \n",
       "10      1    14.10        2.16  2.30        18.0  11.413043           2.95   \n",
       "11      1    14.12        1.48  2.32        16.8   8.152174           2.20   \n",
       "12      1    13.75        1.73  2.41        16.0   6.195652           2.60   \n",
       "13      1    14.75        1.73  2.39        11.4   6.847826           3.10   \n",
       "14      1    14.38        1.87  2.38        12.0  10.434783           3.30   \n",
       "15      1    13.63        1.81  2.70        17.2  13.695652           2.85   \n",
       "16      1    14.30        1.92  2.72        20.0  16.304348           2.80   \n",
       "17      1    13.83        1.57  2.62        20.0  14.673913           2.95   \n",
       "18      1    14.19        1.59  2.48        16.5  12.391304           3.30   \n",
       "19      1    13.64        3.10  2.56        15.2  15.000000           2.70   \n",
       "20      1    14.06        1.63  2.28        16.0  18.260870           3.00   \n",
       "21      1    12.93        3.80  2.65        18.6  10.434783           2.41   \n",
       "22      1    13.71        1.86  2.36        16.6  10.108696           2.61   \n",
       "23      1    12.85        1.60  2.52        17.8   8.152174           2.48   \n",
       "24      1    13.50        1.81  2.61        20.0   8.478261           2.53   \n",
       "25      1    13.05        2.05  3.22        25.0  17.608696           2.63   \n",
       "26      1    13.39        1.77  2.62        16.1   7.500000           2.85   \n",
       "27      1    13.30        1.72  2.14        17.0   7.826087           2.40   \n",
       "28      1    13.87        1.90  2.80        19.4  12.065217           2.95   \n",
       "29      1    14.02        1.68  2.21        16.0   8.478261           2.65   \n",
       "..    ...      ...         ...   ...         ...        ...            ...   \n",
       "148     2    13.32        3.24  2.38        21.5   7.173913           1.93   \n",
       "149     2    13.08        3.90  2.36        21.5  14.021739           1.41   \n",
       "150     2    13.50        3.12  2.62        24.0  17.282609           1.40   \n",
       "151     2    12.79        2.67  2.48        22.0  13.695652           1.48   \n",
       "152     2    13.11        1.90  2.75        25.5  15.000000           2.20   \n",
       "153     2    13.23        3.30  2.28        18.5   9.130435           1.80   \n",
       "154     2    12.58        1.29  2.10        20.0  10.760870           1.48   \n",
       "155     2    13.17        5.19  2.32        22.0   7.500000           1.74   \n",
       "156     2    13.84        4.12  2.38        19.5   6.195652           1.80   \n",
       "157     2    12.45        3.03  2.64        27.0   8.804348           1.90   \n",
       "158     2    14.34        1.68  2.70        25.0   9.130435           2.80   \n",
       "159     2    13.48        1.67  2.64        22.5   6.195652           2.60   \n",
       "160     2    12.36        3.83  2.38        21.0   5.869565           2.30   \n",
       "161     2    13.69        3.26  2.54        20.0  12.065217           1.83   \n",
       "162     2    12.85        3.27  2.58        22.0  11.739130           1.65   \n",
       "163     2    12.96        3.45  2.35        18.5  11.739130           1.39   \n",
       "164     2    13.78        2.76  2.30        22.0   6.521739           1.35   \n",
       "165     2    13.73        4.36  2.26        22.5   5.869565           1.28   \n",
       "166     2    13.45        3.70  2.60        23.0  13.369565           1.70   \n",
       "167     2    12.82        3.37  2.30        19.5   5.869565           1.48   \n",
       "168     2    13.58        2.58  2.69        24.5  11.413043           1.55   \n",
       "169     2    13.40        4.60  2.86        25.0  13.695652           1.98   \n",
       "170     2    12.20        3.03  2.32        19.0   8.478261           1.25   \n",
       "171     2    12.77        2.39  2.28        19.5   5.217391           1.39   \n",
       "172     2    14.16        2.51  2.48        20.0   6.847826           1.68   \n",
       "173     2    13.71        5.65  2.45        20.5   8.152174           1.68   \n",
       "174     2    13.40        3.91  2.48        23.0  10.434783           1.80   \n",
       "175     2    13.27        4.28  2.26        20.0  16.304348           1.59   \n",
       "176     2    13.17        2.59  2.37        20.0  16.304348           1.65   \n",
       "177     2    14.13        4.10  2.74        24.5   8.478261           2.05   \n",
       "\n",
       "     flavonoids  nonflavonoid_phenols  proanthocyanins  color_intensity  \\\n",
       "0          3.06                  0.28             2.29             5.64   \n",
       "1          2.76                  0.26             1.28             4.38   \n",
       "2          3.24                  0.30             2.81             5.68   \n",
       "3          3.49                  0.24             2.18             7.80   \n",
       "4          2.69                  0.39             1.82             4.32   \n",
       "5          3.39                  0.34             1.97             6.75   \n",
       "6          2.52                  0.30             1.98             5.25   \n",
       "7          2.51                  0.31             1.25             5.05   \n",
       "8          2.98                  0.29             1.98             5.20   \n",
       "9          3.15                  0.22             1.85             7.22   \n",
       "10         3.32                  0.22             2.38             5.75   \n",
       "11         2.43                  0.26             1.57             5.00   \n",
       "12         2.76                  0.29             1.81             5.60   \n",
       "13         3.69                  0.43             2.81             5.40   \n",
       "14         3.64                  0.29             2.96             7.50   \n",
       "15         2.91                  0.30             1.46             7.30   \n",
       "16         3.14                  0.33             1.97             6.20   \n",
       "17         3.40                  0.40             1.72             6.60   \n",
       "18         3.93                  0.32             1.86             8.70   \n",
       "19         3.03                  0.17             1.66             5.10   \n",
       "20         3.17                  0.24             2.10             5.65   \n",
       "21         2.41                  0.25             1.98             4.50   \n",
       "22         2.88                  0.27             1.69             3.80   \n",
       "23         2.37                  0.26             1.46             3.93   \n",
       "24         2.61                  0.28             1.66             3.52   \n",
       "25         2.68                  0.47             1.92             3.58   \n",
       "26         2.94                  0.34             1.45             4.80   \n",
       "27         2.19                  0.27             1.35             3.95   \n",
       "28         2.97                  0.37             1.76             4.50   \n",
       "29         2.33                  0.26             1.98             4.70   \n",
       "..          ...                   ...              ...              ...   \n",
       "148        0.76                  0.45             1.25             8.42   \n",
       "149        1.39                  0.34             1.14             9.40   \n",
       "150        1.57                  0.22             1.25             8.60   \n",
       "151        1.36                  0.24             1.26            10.80   \n",
       "152        1.28                  0.26             1.56             7.10   \n",
       "153        0.83                  0.61             1.87            10.52   \n",
       "154        0.58                  0.53             1.40             7.60   \n",
       "155        0.63                  0.61             1.55             7.90   \n",
       "156        0.83                  0.48             1.56             9.01   \n",
       "157        0.58                  0.63             1.14             7.50   \n",
       "158        1.31                  0.53             2.70            13.00   \n",
       "159        1.10                  0.52             2.29            11.75   \n",
       "160        0.92                  0.50             1.04             7.65   \n",
       "161        0.56                  0.50             0.80             5.88   \n",
       "162        0.60                  0.60             0.96             5.58   \n",
       "163        0.70                  0.40             0.94             5.28   \n",
       "164        0.68                  0.41             1.03             9.58   \n",
       "165        0.47                  0.52             1.15             6.62   \n",
       "166        0.92                  0.43             1.46            10.68   \n",
       "167        0.66                  0.40             0.97            10.26   \n",
       "168        0.84                  0.39             1.54             8.66   \n",
       "169        0.96                  0.27             1.11             8.50   \n",
       "170        0.49                  0.40             0.73             5.50   \n",
       "171        0.51                  0.48             0.64             9.90   \n",
       "172        0.70                  0.44             1.24             9.70   \n",
       "173        0.61                  0.52             1.06             7.70   \n",
       "174        0.75                  0.43             1.41             7.30   \n",
       "175        0.69                  0.43             1.35            10.20   \n",
       "176        0.68                  0.53             1.46             9.30   \n",
       "177        0.76                  0.56             1.35             9.20   \n",
       "\n",
       "     color_hue  OD280/OD315    proline  \n",
       "0         1.04         3.92  16.840228  \n",
       "1         1.05         3.40  16.519258  \n",
       "2         1.03         3.17  19.407989  \n",
       "3         0.86         3.45  25.720399  \n",
       "4         1.04         2.93   9.778887  \n",
       "5         1.05         2.85  25.078459  \n",
       "6         1.02         3.58  21.654779  \n",
       "7         1.06         3.58  21.761769  \n",
       "8         1.08         2.85  16.412268  \n",
       "9         1.01         3.55  16.412268  \n",
       "10        1.25         3.17  26.362340  \n",
       "11        1.17         2.82  21.440799  \n",
       "12        1.15         2.90  22.296719  \n",
       "13        1.25         2.73  18.659058  \n",
       "14        1.20         3.00  27.154066  \n",
       "15        1.28         2.88  22.082739  \n",
       "16        1.07         2.65  21.440799  \n",
       "17        1.13         2.57  18.231098  \n",
       "18        1.23         2.82  30.000000  \n",
       "19        0.96         3.36  12.132668  \n",
       "20        1.09         3.71  10.741797  \n",
       "21        1.03         3.52  10.527817  \n",
       "22        1.11         4.00  16.198288  \n",
       "23        1.09         3.63  15.770328  \n",
       "24        1.12         3.82  12.132668  \n",
       "25        1.13         3.20  11.811698  \n",
       "26        0.92         3.22  19.621969  \n",
       "27        1.02         2.77  21.547789  \n",
       "28        1.25         3.40  13.630528  \n",
       "29        1.04         3.59  16.198288  \n",
       "..         ...          ...        ...  \n",
       "148       0.55         1.62   7.960057  \n",
       "149       0.57         1.33   5.820257  \n",
       "150       0.59         1.30   4.750357  \n",
       "151       0.48         1.47   4.322397  \n",
       "152       0.61         1.33   3.145506  \n",
       "153       0.56         1.51   8.495007  \n",
       "154       0.58         1.55   7.746077  \n",
       "155       0.60         1.48   9.564907  \n",
       "156       0.57         1.64   4.322397  \n",
       "157       0.67         1.73  12.881598  \n",
       "158       0.57         1.96   8.174037  \n",
       "159       0.57         1.78   7.318117  \n",
       "160       0.56         1.58   5.178317  \n",
       "161       0.96         1.82   8.601997  \n",
       "162       0.87         2.11   6.248217  \n",
       "163       0.68         1.75   8.495007  \n",
       "164       0.70         1.68   7.211127  \n",
       "165       0.78         1.75   5.178317  \n",
       "166       0.85         1.56   8.922967  \n",
       "167       0.72         1.75   8.708987  \n",
       "168       0.74         1.80  10.099857  \n",
       "169       0.67         1.92   7.532097  \n",
       "170       0.66         1.83   4.964337  \n",
       "171       0.57         1.63   4.108417  \n",
       "172       0.62         1.71   8.174037  \n",
       "173       0.64         1.74   9.885877  \n",
       "174       0.70         1.56  10.099857  \n",
       "175       0.59         1.56  11.918688  \n",
       "176       0.60         1.62  12.025678  \n",
       "177       0.61         1.60   6.034237  \n",
       "\n",
       "[176 rows x 14 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['magnesium'] = (df['magnesium'] - min(df['magnesium']))/ (max(df['magnesium']) - min(df['magnesium'])) * 30\n",
    "df['proline'] = (df['proline'] - min(df['proline']))/ (max(df['proline']) - min(df['proline'])) * 30\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrapping into Pandas-ML\n",
    "\n",
    "Tenslotte stoppen we dit ``DataFrame`` in een ``ModelFrame`` wrapper van [Pandas-ML](http://pandas-ml.readthedocs.io/en/latest/sklearn.html), die het werken met Scikit-Learn sterk vereenvoudigt. Objecten van deze klasse hebben twee handige attributen: ``data`` en ``target``, waarmee respectievelijk de *features* en de *target* van de dataset aangesproken kunnen worden. Voor het eerste deel van dit labo gebruiken we deze attributen nog niet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": [
     "locked"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alkalinity</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavonoids</th>\n",
       "      <th>nonflavonoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>color_hue</th>\n",
       "      <th>OD280/OD315</th>\n",
       "      <th>proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type  alcohol  malic_acid   ash  alkalinity  magnesium  total_phenols  \\\n",
       "0     1    14.23        1.71  2.43        15.6        127           2.80   \n",
       "1     1    13.20        1.78  2.14        11.2        100           2.65   \n",
       "2     1    13.16        2.36  2.67        18.6        101           2.80   \n",
       "3     1    14.37        1.95  2.50        16.8        113           3.85   \n",
       "4     1    13.24        2.59  2.87        21.0        118           2.80   \n",
       "\n",
       "   flavonoids  nonflavonoid_phenols  proanthocyanins  color_intensity  \\\n",
       "0        3.06                  0.28             2.29             5.64   \n",
       "1        2.76                  0.26             1.28             4.38   \n",
       "2        3.24                  0.30             2.81             5.68   \n",
       "3        3.49                  0.24             2.18             7.80   \n",
       "4        2.69                  0.39             1.82             4.32   \n",
       "\n",
       "   color_hue  OD280/OD315  proline  \n",
       "0       1.04         3.92     1065  \n",
       "1       1.05         3.40     1050  \n",
       "2       1.03         3.17     1185  \n",
       "3       0.86         3.45     1480  \n",
       "4       1.04         2.93      735  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wine = pdml.ModelFrame(df.copy(), target='type')\n",
    "df_wine['magnesium'] = df_magnesium_orig     ## restore magnesium\n",
    "df_wine['proline'] = df_proline_orig         ## restore proline\n",
    "df_wine.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Analysis\n",
    "\n",
    "### Descriptive Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "Creëer een ``DataFrame`` met dezelfde kolommen als in ``df``, en als rijen de volgende waarden per kolom:\n",
    "\n",
    "* **aantal** elementen\n",
    "* **gemiddelde** waarde\n",
    "* **standaarddeviatie**\n",
    "* **minimum** waarde\n",
    "* **eerste**, **tweede** en **derde** kwartielen\n",
    "* **maximum** waarde\n",
    "* **variantie**\n",
    "* **kurtosis** (welving) en **skew** (scheefheid)\n",
    "\n",
    "De volgorde van de waarden is niet belangrijk. \n",
    "\n",
    "**Tip:** Gebruik hiervoor *label-based indexing* (``DataFrame.loc[]``) en/of functies die in de theorielessen aan bod zijn gekomen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df2 = df.describe()\n",
    "df2.loc['var'] = df.var()\n",
    "df2.loc['kurt'] = df.kurt()\n",
    "df2.loc['skew'] = df.skew()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "**Question**: Hoeveel samples zitten er van elk wijnras in deze database? Zijn de klassen gebalanceerd?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alkalinity</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavonoids</th>\n",
       "      <th>nonflavonoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>color_hue</th>\n",
       "      <th>OD280/OD315</th>\n",
       "      <th>proline</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>58</td>\n",
       "      <td>58</td>\n",
       "      <td>58</td>\n",
       "      <td>58</td>\n",
       "      <td>58</td>\n",
       "      <td>58</td>\n",
       "      <td>58</td>\n",
       "      <td>58</td>\n",
       "      <td>58</td>\n",
       "      <td>58</td>\n",
       "      <td>58</td>\n",
       "      <td>58</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>70</td>\n",
       "      <td>70</td>\n",
       "      <td>70</td>\n",
       "      <td>70</td>\n",
       "      <td>70</td>\n",
       "      <td>70</td>\n",
       "      <td>70</td>\n",
       "      <td>70</td>\n",
       "      <td>70</td>\n",
       "      <td>70</td>\n",
       "      <td>70</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      alcohol  malic_acid  ash  alkalinity  magnesium  total_phenols  \\\n",
       "type                                                                   \n",
       "1          58          58   58          58         58             58   \n",
       "2          48          48   48          48         48             48   \n",
       "3          70          70   70          70         70             70   \n",
       "\n",
       "      flavonoids  nonflavonoid_phenols  proanthocyanins  color_intensity  \\\n",
       "type                                                                       \n",
       "1             58                    58               58               58   \n",
       "2             48                    48               48               48   \n",
       "3             70                    70               70               70   \n",
       "\n",
       "      color_hue  OD280/OD315  proline  \n",
       "type                                   \n",
       "1            58           58       58  \n",
       "2            48           48       48  \n",
       "3            70           70       70  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('type').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "**Question**: Welk(e) van deze kolommen heeft/hebben het grootste aantal *outliers* (waarden die meer dan 2.5 keer de standaarddeviatie verwijderd zijn van het steekproefgemiddelde)?\n",
    "\n",
    "**TIP**: Gebruik hiervoor *boolean indexing* en één van de aggregaatfuncties uit de vorige tabel. Let op: er kunnen zowel lage als hoge outliers tussenzitten!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alkalinity</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavonoids</th>\n",
       "      <th>nonflavonoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>color_hue</th>\n",
       "      <th>OD280/OD315</th>\n",
       "      <th>proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>18.586957</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>16.840228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>9.782609</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>16.519258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>10.108696</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>19.407989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>14.021739</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>25.720399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>15.652174</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>9.778887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>14.20</td>\n",
       "      <td>1.76</td>\n",
       "      <td>2.45</td>\n",
       "      <td>15.2</td>\n",
       "      <td>13.695652</td>\n",
       "      <td>3.27</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.97</td>\n",
       "      <td>6.75</td>\n",
       "      <td>1.05</td>\n",
       "      <td>2.85</td>\n",
       "      <td>25.078459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>14.39</td>\n",
       "      <td>1.87</td>\n",
       "      <td>2.45</td>\n",
       "      <td>14.6</td>\n",
       "      <td>8.478261</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2.52</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.98</td>\n",
       "      <td>5.25</td>\n",
       "      <td>1.02</td>\n",
       "      <td>3.58</td>\n",
       "      <td>21.654779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>14.06</td>\n",
       "      <td>2.15</td>\n",
       "      <td>2.61</td>\n",
       "      <td>17.6</td>\n",
       "      <td>16.630435</td>\n",
       "      <td>2.60</td>\n",
       "      <td>2.51</td>\n",
       "      <td>0.31</td>\n",
       "      <td>1.25</td>\n",
       "      <td>5.05</td>\n",
       "      <td>1.06</td>\n",
       "      <td>3.58</td>\n",
       "      <td>21.761769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>14.83</td>\n",
       "      <td>1.64</td>\n",
       "      <td>2.17</td>\n",
       "      <td>14.0</td>\n",
       "      <td>8.804348</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.98</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.98</td>\n",
       "      <td>5.20</td>\n",
       "      <td>1.08</td>\n",
       "      <td>2.85</td>\n",
       "      <td>16.412268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>13.86</td>\n",
       "      <td>1.35</td>\n",
       "      <td>2.27</td>\n",
       "      <td>16.0</td>\n",
       "      <td>9.130435</td>\n",
       "      <td>2.98</td>\n",
       "      <td>3.15</td>\n",
       "      <td>0.22</td>\n",
       "      <td>1.85</td>\n",
       "      <td>7.22</td>\n",
       "      <td>1.01</td>\n",
       "      <td>3.55</td>\n",
       "      <td>16.412268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>14.10</td>\n",
       "      <td>2.16</td>\n",
       "      <td>2.30</td>\n",
       "      <td>18.0</td>\n",
       "      <td>11.413043</td>\n",
       "      <td>2.95</td>\n",
       "      <td>3.32</td>\n",
       "      <td>0.22</td>\n",
       "      <td>2.38</td>\n",
       "      <td>5.75</td>\n",
       "      <td>1.25</td>\n",
       "      <td>3.17</td>\n",
       "      <td>26.362340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>14.12</td>\n",
       "      <td>1.48</td>\n",
       "      <td>2.32</td>\n",
       "      <td>16.8</td>\n",
       "      <td>8.152174</td>\n",
       "      <td>2.20</td>\n",
       "      <td>2.43</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.57</td>\n",
       "      <td>5.00</td>\n",
       "      <td>1.17</td>\n",
       "      <td>2.82</td>\n",
       "      <td>21.440799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>13.75</td>\n",
       "      <td>1.73</td>\n",
       "      <td>2.41</td>\n",
       "      <td>16.0</td>\n",
       "      <td>6.195652</td>\n",
       "      <td>2.60</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.81</td>\n",
       "      <td>5.60</td>\n",
       "      <td>1.15</td>\n",
       "      <td>2.90</td>\n",
       "      <td>22.296719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>14.75</td>\n",
       "      <td>1.73</td>\n",
       "      <td>2.39</td>\n",
       "      <td>11.4</td>\n",
       "      <td>6.847826</td>\n",
       "      <td>3.10</td>\n",
       "      <td>3.69</td>\n",
       "      <td>0.43</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.40</td>\n",
       "      <td>1.25</td>\n",
       "      <td>2.73</td>\n",
       "      <td>18.659058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>14.38</td>\n",
       "      <td>1.87</td>\n",
       "      <td>2.38</td>\n",
       "      <td>12.0</td>\n",
       "      <td>10.434783</td>\n",
       "      <td>3.30</td>\n",
       "      <td>3.64</td>\n",
       "      <td>0.29</td>\n",
       "      <td>2.96</td>\n",
       "      <td>7.50</td>\n",
       "      <td>1.20</td>\n",
       "      <td>3.00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>13.63</td>\n",
       "      <td>1.81</td>\n",
       "      <td>2.70</td>\n",
       "      <td>17.2</td>\n",
       "      <td>13.695652</td>\n",
       "      <td>2.85</td>\n",
       "      <td>2.91</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.46</td>\n",
       "      <td>7.30</td>\n",
       "      <td>1.28</td>\n",
       "      <td>2.88</td>\n",
       "      <td>22.082739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>14.30</td>\n",
       "      <td>1.92</td>\n",
       "      <td>2.72</td>\n",
       "      <td>20.0</td>\n",
       "      <td>16.304348</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.14</td>\n",
       "      <td>0.33</td>\n",
       "      <td>1.97</td>\n",
       "      <td>6.20</td>\n",
       "      <td>1.07</td>\n",
       "      <td>2.65</td>\n",
       "      <td>21.440799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>13.83</td>\n",
       "      <td>1.57</td>\n",
       "      <td>2.62</td>\n",
       "      <td>20.0</td>\n",
       "      <td>14.673913</td>\n",
       "      <td>2.95</td>\n",
       "      <td>3.40</td>\n",
       "      <td>0.40</td>\n",
       "      <td>1.72</td>\n",
       "      <td>6.60</td>\n",
       "      <td>1.13</td>\n",
       "      <td>2.57</td>\n",
       "      <td>18.231098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>14.19</td>\n",
       "      <td>1.59</td>\n",
       "      <td>2.48</td>\n",
       "      <td>16.5</td>\n",
       "      <td>12.391304</td>\n",
       "      <td>3.30</td>\n",
       "      <td>3.93</td>\n",
       "      <td>0.32</td>\n",
       "      <td>1.86</td>\n",
       "      <td>8.70</td>\n",
       "      <td>1.23</td>\n",
       "      <td>2.82</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>13.64</td>\n",
       "      <td>3.10</td>\n",
       "      <td>2.56</td>\n",
       "      <td>15.2</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>2.70</td>\n",
       "      <td>3.03</td>\n",
       "      <td>0.17</td>\n",
       "      <td>1.66</td>\n",
       "      <td>5.10</td>\n",
       "      <td>0.96</td>\n",
       "      <td>3.36</td>\n",
       "      <td>12.132668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>14.06</td>\n",
       "      <td>1.63</td>\n",
       "      <td>2.28</td>\n",
       "      <td>16.0</td>\n",
       "      <td>18.260870</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.17</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.10</td>\n",
       "      <td>5.65</td>\n",
       "      <td>1.09</td>\n",
       "      <td>3.71</td>\n",
       "      <td>10.741797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>12.93</td>\n",
       "      <td>3.80</td>\n",
       "      <td>2.65</td>\n",
       "      <td>18.6</td>\n",
       "      <td>10.434783</td>\n",
       "      <td>2.41</td>\n",
       "      <td>2.41</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.98</td>\n",
       "      <td>4.50</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.52</td>\n",
       "      <td>10.527817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>13.71</td>\n",
       "      <td>1.86</td>\n",
       "      <td>2.36</td>\n",
       "      <td>16.6</td>\n",
       "      <td>10.108696</td>\n",
       "      <td>2.61</td>\n",
       "      <td>2.88</td>\n",
       "      <td>0.27</td>\n",
       "      <td>1.69</td>\n",
       "      <td>3.80</td>\n",
       "      <td>1.11</td>\n",
       "      <td>4.00</td>\n",
       "      <td>16.198288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>12.85</td>\n",
       "      <td>1.60</td>\n",
       "      <td>2.52</td>\n",
       "      <td>17.8</td>\n",
       "      <td>8.152174</td>\n",
       "      <td>2.48</td>\n",
       "      <td>2.37</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.46</td>\n",
       "      <td>3.93</td>\n",
       "      <td>1.09</td>\n",
       "      <td>3.63</td>\n",
       "      <td>15.770328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>13.50</td>\n",
       "      <td>1.81</td>\n",
       "      <td>2.61</td>\n",
       "      <td>20.0</td>\n",
       "      <td>8.478261</td>\n",
       "      <td>2.53</td>\n",
       "      <td>2.61</td>\n",
       "      <td>0.28</td>\n",
       "      <td>1.66</td>\n",
       "      <td>3.52</td>\n",
       "      <td>1.12</td>\n",
       "      <td>3.82</td>\n",
       "      <td>12.132668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>13.05</td>\n",
       "      <td>2.05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.0</td>\n",
       "      <td>17.608696</td>\n",
       "      <td>2.63</td>\n",
       "      <td>2.68</td>\n",
       "      <td>0.47</td>\n",
       "      <td>1.92</td>\n",
       "      <td>3.58</td>\n",
       "      <td>1.13</td>\n",
       "      <td>3.20</td>\n",
       "      <td>11.811698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>13.39</td>\n",
       "      <td>1.77</td>\n",
       "      <td>2.62</td>\n",
       "      <td>16.1</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>2.85</td>\n",
       "      <td>2.94</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.45</td>\n",
       "      <td>4.80</td>\n",
       "      <td>0.92</td>\n",
       "      <td>3.22</td>\n",
       "      <td>19.621969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>13.30</td>\n",
       "      <td>1.72</td>\n",
       "      <td>2.14</td>\n",
       "      <td>17.0</td>\n",
       "      <td>7.826087</td>\n",
       "      <td>2.40</td>\n",
       "      <td>2.19</td>\n",
       "      <td>0.27</td>\n",
       "      <td>1.35</td>\n",
       "      <td>3.95</td>\n",
       "      <td>1.02</td>\n",
       "      <td>2.77</td>\n",
       "      <td>21.547789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>13.87</td>\n",
       "      <td>1.90</td>\n",
       "      <td>2.80</td>\n",
       "      <td>19.4</td>\n",
       "      <td>12.065217</td>\n",
       "      <td>2.95</td>\n",
       "      <td>2.97</td>\n",
       "      <td>0.37</td>\n",
       "      <td>1.76</td>\n",
       "      <td>4.50</td>\n",
       "      <td>1.25</td>\n",
       "      <td>3.40</td>\n",
       "      <td>13.630528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>14.02</td>\n",
       "      <td>1.68</td>\n",
       "      <td>2.21</td>\n",
       "      <td>16.0</td>\n",
       "      <td>8.478261</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.33</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.98</td>\n",
       "      <td>4.70</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.59</td>\n",
       "      <td>16.198288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>2</td>\n",
       "      <td>13.32</td>\n",
       "      <td>3.24</td>\n",
       "      <td>2.38</td>\n",
       "      <td>21.5</td>\n",
       "      <td>7.173913</td>\n",
       "      <td>1.93</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.45</td>\n",
       "      <td>1.25</td>\n",
       "      <td>8.42</td>\n",
       "      <td>0.55</td>\n",
       "      <td>1.62</td>\n",
       "      <td>7.960057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>2</td>\n",
       "      <td>13.08</td>\n",
       "      <td>3.90</td>\n",
       "      <td>2.36</td>\n",
       "      <td>21.5</td>\n",
       "      <td>14.021739</td>\n",
       "      <td>1.41</td>\n",
       "      <td>1.39</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.14</td>\n",
       "      <td>9.40</td>\n",
       "      <td>0.57</td>\n",
       "      <td>1.33</td>\n",
       "      <td>5.820257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>2</td>\n",
       "      <td>13.50</td>\n",
       "      <td>3.12</td>\n",
       "      <td>2.62</td>\n",
       "      <td>24.0</td>\n",
       "      <td>17.282609</td>\n",
       "      <td>1.40</td>\n",
       "      <td>1.57</td>\n",
       "      <td>0.22</td>\n",
       "      <td>1.25</td>\n",
       "      <td>8.60</td>\n",
       "      <td>0.59</td>\n",
       "      <td>1.30</td>\n",
       "      <td>4.750357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>2</td>\n",
       "      <td>12.79</td>\n",
       "      <td>2.67</td>\n",
       "      <td>2.48</td>\n",
       "      <td>22.0</td>\n",
       "      <td>13.695652</td>\n",
       "      <td>1.48</td>\n",
       "      <td>1.36</td>\n",
       "      <td>0.24</td>\n",
       "      <td>1.26</td>\n",
       "      <td>10.80</td>\n",
       "      <td>0.48</td>\n",
       "      <td>1.47</td>\n",
       "      <td>4.322397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>2</td>\n",
       "      <td>13.11</td>\n",
       "      <td>1.90</td>\n",
       "      <td>2.75</td>\n",
       "      <td>25.5</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>2.20</td>\n",
       "      <td>1.28</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.56</td>\n",
       "      <td>7.10</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1.33</td>\n",
       "      <td>3.145506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>2</td>\n",
       "      <td>13.23</td>\n",
       "      <td>3.30</td>\n",
       "      <td>2.28</td>\n",
       "      <td>18.5</td>\n",
       "      <td>9.130435</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1.87</td>\n",
       "      <td>10.52</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.51</td>\n",
       "      <td>8.495007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>2</td>\n",
       "      <td>12.58</td>\n",
       "      <td>1.29</td>\n",
       "      <td>2.10</td>\n",
       "      <td>20.0</td>\n",
       "      <td>10.760870</td>\n",
       "      <td>1.48</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1.40</td>\n",
       "      <td>7.60</td>\n",
       "      <td>0.58</td>\n",
       "      <td>1.55</td>\n",
       "      <td>7.746077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>2</td>\n",
       "      <td>13.17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.32</td>\n",
       "      <td>22.0</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>1.74</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1.55</td>\n",
       "      <td>7.90</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.48</td>\n",
       "      <td>9.564907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>2</td>\n",
       "      <td>13.84</td>\n",
       "      <td>4.12</td>\n",
       "      <td>2.38</td>\n",
       "      <td>19.5</td>\n",
       "      <td>6.195652</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.48</td>\n",
       "      <td>1.56</td>\n",
       "      <td>9.01</td>\n",
       "      <td>0.57</td>\n",
       "      <td>1.64</td>\n",
       "      <td>4.322397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>2</td>\n",
       "      <td>12.45</td>\n",
       "      <td>3.03</td>\n",
       "      <td>2.64</td>\n",
       "      <td>27.0</td>\n",
       "      <td>8.804348</td>\n",
       "      <td>1.90</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.63</td>\n",
       "      <td>1.14</td>\n",
       "      <td>7.50</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1.73</td>\n",
       "      <td>12.881598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>2</td>\n",
       "      <td>14.34</td>\n",
       "      <td>1.68</td>\n",
       "      <td>2.70</td>\n",
       "      <td>25.0</td>\n",
       "      <td>9.130435</td>\n",
       "      <td>2.80</td>\n",
       "      <td>1.31</td>\n",
       "      <td>0.53</td>\n",
       "      <td>2.70</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.57</td>\n",
       "      <td>1.96</td>\n",
       "      <td>8.174037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>2</td>\n",
       "      <td>13.48</td>\n",
       "      <td>1.67</td>\n",
       "      <td>2.64</td>\n",
       "      <td>22.5</td>\n",
       "      <td>6.195652</td>\n",
       "      <td>2.60</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.52</td>\n",
       "      <td>2.29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.57</td>\n",
       "      <td>1.78</td>\n",
       "      <td>7.318117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>2</td>\n",
       "      <td>12.36</td>\n",
       "      <td>3.83</td>\n",
       "      <td>2.38</td>\n",
       "      <td>21.0</td>\n",
       "      <td>5.869565</td>\n",
       "      <td>2.30</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.04</td>\n",
       "      <td>7.65</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.58</td>\n",
       "      <td>5.178317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>2</td>\n",
       "      <td>13.69</td>\n",
       "      <td>3.26</td>\n",
       "      <td>2.54</td>\n",
       "      <td>20.0</td>\n",
       "      <td>12.065217</td>\n",
       "      <td>1.83</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.80</td>\n",
       "      <td>5.88</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1.82</td>\n",
       "      <td>8.601997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>2</td>\n",
       "      <td>12.85</td>\n",
       "      <td>3.27</td>\n",
       "      <td>2.58</td>\n",
       "      <td>22.0</td>\n",
       "      <td>11.739130</td>\n",
       "      <td>1.65</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.96</td>\n",
       "      <td>5.58</td>\n",
       "      <td>0.87</td>\n",
       "      <td>2.11</td>\n",
       "      <td>6.248217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>2</td>\n",
       "      <td>12.96</td>\n",
       "      <td>3.45</td>\n",
       "      <td>2.35</td>\n",
       "      <td>18.5</td>\n",
       "      <td>11.739130</td>\n",
       "      <td>1.39</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.94</td>\n",
       "      <td>5.28</td>\n",
       "      <td>0.68</td>\n",
       "      <td>1.75</td>\n",
       "      <td>8.495007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>2</td>\n",
       "      <td>13.78</td>\n",
       "      <td>2.76</td>\n",
       "      <td>2.30</td>\n",
       "      <td>22.0</td>\n",
       "      <td>6.521739</td>\n",
       "      <td>1.35</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.41</td>\n",
       "      <td>1.03</td>\n",
       "      <td>9.58</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.68</td>\n",
       "      <td>7.211127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>2</td>\n",
       "      <td>13.73</td>\n",
       "      <td>4.36</td>\n",
       "      <td>2.26</td>\n",
       "      <td>22.5</td>\n",
       "      <td>5.869565</td>\n",
       "      <td>1.28</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.52</td>\n",
       "      <td>1.15</td>\n",
       "      <td>6.62</td>\n",
       "      <td>0.78</td>\n",
       "      <td>1.75</td>\n",
       "      <td>5.178317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>2</td>\n",
       "      <td>13.45</td>\n",
       "      <td>3.70</td>\n",
       "      <td>2.60</td>\n",
       "      <td>23.0</td>\n",
       "      <td>13.369565</td>\n",
       "      <td>1.70</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.46</td>\n",
       "      <td>10.68</td>\n",
       "      <td>0.85</td>\n",
       "      <td>1.56</td>\n",
       "      <td>8.922967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>2</td>\n",
       "      <td>12.82</td>\n",
       "      <td>3.37</td>\n",
       "      <td>2.30</td>\n",
       "      <td>19.5</td>\n",
       "      <td>5.869565</td>\n",
       "      <td>1.48</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.97</td>\n",
       "      <td>10.26</td>\n",
       "      <td>0.72</td>\n",
       "      <td>1.75</td>\n",
       "      <td>8.708987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>2</td>\n",
       "      <td>13.58</td>\n",
       "      <td>2.58</td>\n",
       "      <td>2.69</td>\n",
       "      <td>24.5</td>\n",
       "      <td>11.413043</td>\n",
       "      <td>1.55</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.54</td>\n",
       "      <td>8.66</td>\n",
       "      <td>0.74</td>\n",
       "      <td>1.80</td>\n",
       "      <td>10.099857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>2</td>\n",
       "      <td>13.40</td>\n",
       "      <td>4.60</td>\n",
       "      <td>2.86</td>\n",
       "      <td>25.0</td>\n",
       "      <td>13.695652</td>\n",
       "      <td>1.98</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.27</td>\n",
       "      <td>1.11</td>\n",
       "      <td>8.50</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1.92</td>\n",
       "      <td>7.532097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>2</td>\n",
       "      <td>12.20</td>\n",
       "      <td>3.03</td>\n",
       "      <td>2.32</td>\n",
       "      <td>19.0</td>\n",
       "      <td>8.478261</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.73</td>\n",
       "      <td>5.50</td>\n",
       "      <td>0.66</td>\n",
       "      <td>1.83</td>\n",
       "      <td>4.964337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>2</td>\n",
       "      <td>12.77</td>\n",
       "      <td>2.39</td>\n",
       "      <td>2.28</td>\n",
       "      <td>19.5</td>\n",
       "      <td>5.217391</td>\n",
       "      <td>1.39</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.64</td>\n",
       "      <td>9.90</td>\n",
       "      <td>0.57</td>\n",
       "      <td>1.63</td>\n",
       "      <td>4.108417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>2</td>\n",
       "      <td>14.16</td>\n",
       "      <td>2.51</td>\n",
       "      <td>2.48</td>\n",
       "      <td>20.0</td>\n",
       "      <td>6.847826</td>\n",
       "      <td>1.68</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.44</td>\n",
       "      <td>1.24</td>\n",
       "      <td>9.70</td>\n",
       "      <td>0.62</td>\n",
       "      <td>1.71</td>\n",
       "      <td>8.174037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>2</td>\n",
       "      <td>13.71</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.45</td>\n",
       "      <td>20.5</td>\n",
       "      <td>8.152174</td>\n",
       "      <td>1.68</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.52</td>\n",
       "      <td>1.06</td>\n",
       "      <td>7.70</td>\n",
       "      <td>0.64</td>\n",
       "      <td>1.74</td>\n",
       "      <td>9.885877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>2</td>\n",
       "      <td>13.40</td>\n",
       "      <td>3.91</td>\n",
       "      <td>2.48</td>\n",
       "      <td>23.0</td>\n",
       "      <td>10.434783</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.41</td>\n",
       "      <td>7.30</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.56</td>\n",
       "      <td>10.099857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>2</td>\n",
       "      <td>13.27</td>\n",
       "      <td>4.28</td>\n",
       "      <td>2.26</td>\n",
       "      <td>20.0</td>\n",
       "      <td>16.304348</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.35</td>\n",
       "      <td>10.20</td>\n",
       "      <td>0.59</td>\n",
       "      <td>1.56</td>\n",
       "      <td>11.918688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>2</td>\n",
       "      <td>13.17</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.37</td>\n",
       "      <td>20.0</td>\n",
       "      <td>16.304348</td>\n",
       "      <td>1.65</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1.46</td>\n",
       "      <td>9.30</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.62</td>\n",
       "      <td>12.025678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>2</td>\n",
       "      <td>14.13</td>\n",
       "      <td>4.10</td>\n",
       "      <td>2.74</td>\n",
       "      <td>24.5</td>\n",
       "      <td>8.478261</td>\n",
       "      <td>2.05</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.35</td>\n",
       "      <td>9.20</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1.60</td>\n",
       "      <td>6.034237</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>176 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     type  alcohol  malic_acid   ash  alkalinity  magnesium  total_phenols  \\\n",
       "0       1    14.23        1.71  2.43        15.6  18.586957           2.80   \n",
       "1       1    13.20        1.78  2.14        11.2   9.782609           2.65   \n",
       "2       1    13.16        2.36  2.67        18.6  10.108696           2.80   \n",
       "3       1    14.37        1.95  2.50        16.8  14.021739           3.85   \n",
       "4       1    13.24        2.59  2.87        21.0  15.652174           2.80   \n",
       "5       1    14.20        1.76  2.45        15.2  13.695652           3.27   \n",
       "6       1    14.39        1.87  2.45        14.6   8.478261           2.50   \n",
       "7       1    14.06        2.15  2.61        17.6  16.630435           2.60   \n",
       "8       1    14.83        1.64  2.17        14.0   8.804348           2.80   \n",
       "9       1    13.86        1.35  2.27        16.0   9.130435           2.98   \n",
       "10      1    14.10        2.16  2.30        18.0  11.413043           2.95   \n",
       "11      1    14.12        1.48  2.32        16.8   8.152174           2.20   \n",
       "12      1    13.75        1.73  2.41        16.0   6.195652           2.60   \n",
       "13      1    14.75        1.73  2.39        11.4   6.847826           3.10   \n",
       "14      1    14.38        1.87  2.38        12.0  10.434783           3.30   \n",
       "15      1    13.63        1.81  2.70        17.2  13.695652           2.85   \n",
       "16      1    14.30        1.92  2.72        20.0  16.304348           2.80   \n",
       "17      1    13.83        1.57  2.62        20.0  14.673913           2.95   \n",
       "18      1    14.19        1.59  2.48        16.5  12.391304           3.30   \n",
       "19      1    13.64        3.10  2.56        15.2  15.000000           2.70   \n",
       "20      1    14.06        1.63  2.28        16.0  18.260870           3.00   \n",
       "21      1    12.93        3.80  2.65        18.6  10.434783           2.41   \n",
       "22      1    13.71        1.86  2.36        16.6  10.108696           2.61   \n",
       "23      1    12.85        1.60  2.52        17.8   8.152174           2.48   \n",
       "24      1    13.50        1.81  2.61        20.0   8.478261           2.53   \n",
       "25      1    13.05        2.05   NaN        25.0  17.608696           2.63   \n",
       "26      1    13.39        1.77  2.62        16.1   7.500000           2.85   \n",
       "27      1    13.30        1.72  2.14        17.0   7.826087           2.40   \n",
       "28      1    13.87        1.90  2.80        19.4  12.065217           2.95   \n",
       "29      1    14.02        1.68  2.21        16.0   8.478261           2.65   \n",
       "..    ...      ...         ...   ...         ...        ...            ...   \n",
       "148     2    13.32        3.24  2.38        21.5   7.173913           1.93   \n",
       "149     2    13.08        3.90  2.36        21.5  14.021739           1.41   \n",
       "150     2    13.50        3.12  2.62        24.0  17.282609           1.40   \n",
       "151     2    12.79        2.67  2.48        22.0  13.695652           1.48   \n",
       "152     2    13.11        1.90  2.75        25.5  15.000000           2.20   \n",
       "153     2    13.23        3.30  2.28        18.5   9.130435           1.80   \n",
       "154     2    12.58        1.29  2.10        20.0  10.760870           1.48   \n",
       "155     2    13.17         NaN  2.32        22.0   7.500000           1.74   \n",
       "156     2    13.84        4.12  2.38        19.5   6.195652           1.80   \n",
       "157     2    12.45        3.03  2.64        27.0   8.804348           1.90   \n",
       "158     2    14.34        1.68  2.70        25.0   9.130435           2.80   \n",
       "159     2    13.48        1.67  2.64        22.5   6.195652           2.60   \n",
       "160     2    12.36        3.83  2.38        21.0   5.869565           2.30   \n",
       "161     2    13.69        3.26  2.54        20.0  12.065217           1.83   \n",
       "162     2    12.85        3.27  2.58        22.0  11.739130           1.65   \n",
       "163     2    12.96        3.45  2.35        18.5  11.739130           1.39   \n",
       "164     2    13.78        2.76  2.30        22.0   6.521739           1.35   \n",
       "165     2    13.73        4.36  2.26        22.5   5.869565           1.28   \n",
       "166     2    13.45        3.70  2.60        23.0  13.369565           1.70   \n",
       "167     2    12.82        3.37  2.30        19.5   5.869565           1.48   \n",
       "168     2    13.58        2.58  2.69        24.5  11.413043           1.55   \n",
       "169     2    13.40        4.60  2.86        25.0  13.695652           1.98   \n",
       "170     2    12.20        3.03  2.32        19.0   8.478261           1.25   \n",
       "171     2    12.77        2.39  2.28        19.5   5.217391           1.39   \n",
       "172     2    14.16        2.51  2.48        20.0   6.847826           1.68   \n",
       "173     2    13.71         NaN  2.45        20.5   8.152174           1.68   \n",
       "174     2    13.40        3.91  2.48        23.0  10.434783           1.80   \n",
       "175     2    13.27        4.28  2.26        20.0  16.304348           1.59   \n",
       "176     2    13.17        2.59  2.37        20.0  16.304348           1.65   \n",
       "177     2    14.13        4.10  2.74        24.5   8.478261           2.05   \n",
       "\n",
       "     flavonoids  nonflavonoid_phenols  proanthocyanins  color_intensity  \\\n",
       "0          3.06                  0.28             2.29             5.64   \n",
       "1          2.76                  0.26             1.28             4.38   \n",
       "2          3.24                  0.30             2.81             5.68   \n",
       "3          3.49                  0.24             2.18             7.80   \n",
       "4          2.69                  0.39             1.82             4.32   \n",
       "5          3.39                  0.34             1.97             6.75   \n",
       "6          2.52                  0.30             1.98             5.25   \n",
       "7          2.51                  0.31             1.25             5.05   \n",
       "8          2.98                  0.29             1.98             5.20   \n",
       "9          3.15                  0.22             1.85             7.22   \n",
       "10         3.32                  0.22             2.38             5.75   \n",
       "11         2.43                  0.26             1.57             5.00   \n",
       "12         2.76                  0.29             1.81             5.60   \n",
       "13         3.69                  0.43             2.81             5.40   \n",
       "14         3.64                  0.29             2.96             7.50   \n",
       "15         2.91                  0.30             1.46             7.30   \n",
       "16         3.14                  0.33             1.97             6.20   \n",
       "17         3.40                  0.40             1.72             6.60   \n",
       "18         3.93                  0.32             1.86             8.70   \n",
       "19         3.03                  0.17             1.66             5.10   \n",
       "20         3.17                  0.24             2.10             5.65   \n",
       "21         2.41                  0.25             1.98             4.50   \n",
       "22         2.88                  0.27             1.69             3.80   \n",
       "23         2.37                  0.26             1.46             3.93   \n",
       "24         2.61                  0.28             1.66             3.52   \n",
       "25         2.68                  0.47             1.92             3.58   \n",
       "26         2.94                  0.34             1.45             4.80   \n",
       "27         2.19                  0.27             1.35             3.95   \n",
       "28         2.97                  0.37             1.76             4.50   \n",
       "29         2.33                  0.26             1.98             4.70   \n",
       "..          ...                   ...              ...              ...   \n",
       "148        0.76                  0.45             1.25             8.42   \n",
       "149        1.39                  0.34             1.14             9.40   \n",
       "150        1.57                  0.22             1.25             8.60   \n",
       "151        1.36                  0.24             1.26            10.80   \n",
       "152        1.28                  0.26             1.56             7.10   \n",
       "153        0.83                  0.61             1.87            10.52   \n",
       "154        0.58                  0.53             1.40             7.60   \n",
       "155        0.63                  0.61             1.55             7.90   \n",
       "156        0.83                  0.48             1.56             9.01   \n",
       "157        0.58                  0.63             1.14             7.50   \n",
       "158        1.31                  0.53             2.70              NaN   \n",
       "159        1.10                  0.52             2.29              NaN   \n",
       "160        0.92                  0.50             1.04             7.65   \n",
       "161        0.56                  0.50             0.80             5.88   \n",
       "162        0.60                  0.60             0.96             5.58   \n",
       "163        0.70                  0.40             0.94             5.28   \n",
       "164        0.68                  0.41             1.03             9.58   \n",
       "165        0.47                  0.52             1.15             6.62   \n",
       "166        0.92                  0.43             1.46            10.68   \n",
       "167        0.66                  0.40             0.97            10.26   \n",
       "168        0.84                  0.39             1.54             8.66   \n",
       "169        0.96                  0.27             1.11             8.50   \n",
       "170        0.49                  0.40             0.73             5.50   \n",
       "171        0.51                  0.48             0.64             9.90   \n",
       "172        0.70                  0.44             1.24             9.70   \n",
       "173        0.61                  0.52             1.06             7.70   \n",
       "174        0.75                  0.43             1.41             7.30   \n",
       "175        0.69                  0.43             1.35            10.20   \n",
       "176        0.68                  0.53             1.46             9.30   \n",
       "177        0.76                  0.56             1.35             9.20   \n",
       "\n",
       "     color_hue  OD280/OD315    proline  \n",
       "0         1.04         3.92  16.840228  \n",
       "1         1.05         3.40  16.519258  \n",
       "2         1.03         3.17  19.407989  \n",
       "3         0.86         3.45  25.720399  \n",
       "4         1.04         2.93   9.778887  \n",
       "5         1.05         2.85  25.078459  \n",
       "6         1.02         3.58  21.654779  \n",
       "7         1.06         3.58  21.761769  \n",
       "8         1.08         2.85  16.412268  \n",
       "9         1.01         3.55  16.412268  \n",
       "10        1.25         3.17  26.362340  \n",
       "11        1.17         2.82  21.440799  \n",
       "12        1.15         2.90  22.296719  \n",
       "13        1.25         2.73  18.659058  \n",
       "14        1.20         3.00        NaN  \n",
       "15        1.28         2.88  22.082739  \n",
       "16        1.07         2.65  21.440799  \n",
       "17        1.13         2.57  18.231098  \n",
       "18        1.23         2.82        NaN  \n",
       "19        0.96         3.36  12.132668  \n",
       "20        1.09         3.71  10.741797  \n",
       "21        1.03         3.52  10.527817  \n",
       "22        1.11         4.00  16.198288  \n",
       "23        1.09         3.63  15.770328  \n",
       "24        1.12         3.82  12.132668  \n",
       "25        1.13         3.20  11.811698  \n",
       "26        0.92         3.22  19.621969  \n",
       "27        1.02         2.77  21.547789  \n",
       "28        1.25         3.40  13.630528  \n",
       "29        1.04         3.59  16.198288  \n",
       "..         ...          ...        ...  \n",
       "148       0.55         1.62   7.960057  \n",
       "149       0.57         1.33   5.820257  \n",
       "150       0.59         1.30   4.750357  \n",
       "151       0.48         1.47   4.322397  \n",
       "152       0.61         1.33   3.145506  \n",
       "153       0.56         1.51   8.495007  \n",
       "154       0.58         1.55   7.746077  \n",
       "155       0.60         1.48   9.564907  \n",
       "156       0.57         1.64   4.322397  \n",
       "157       0.67         1.73  12.881598  \n",
       "158       0.57         1.96   8.174037  \n",
       "159       0.57         1.78   7.318117  \n",
       "160       0.56         1.58   5.178317  \n",
       "161       0.96         1.82   8.601997  \n",
       "162       0.87         2.11   6.248217  \n",
       "163       0.68         1.75   8.495007  \n",
       "164       0.70         1.68   7.211127  \n",
       "165       0.78         1.75   5.178317  \n",
       "166       0.85         1.56   8.922967  \n",
       "167       0.72         1.75   8.708987  \n",
       "168       0.74         1.80  10.099857  \n",
       "169       0.67         1.92   7.532097  \n",
       "170       0.66         1.83   4.964337  \n",
       "171       0.57         1.63   4.108417  \n",
       "172       0.62         1.71   8.174037  \n",
       "173       0.64         1.74   9.885877  \n",
       "174       0.70         1.56  10.099857  \n",
       "175       0.59         1.56  11.918688  \n",
       "176       0.60         1.62  12.025678  \n",
       "177       0.61         1.60   6.034237  \n",
       "\n",
       "[176 rows x 14 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[np.abs(df- df.mean()) <= (2.5*df.std())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "**Question**: Heeft de herschaling uit één van de vorige stappen invloed gehad op de outliers? Waarom (niet)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation\n",
    "\n",
    "Voor de meeste mensen is het gemakkelijker om een beter inzicht in de aard van de data te krijgen als deze grafisch voorgesteld wordt. Het Python ecosysteem bevat een groot aantal toolkits die hiervoor gebruikt kunnen worden, maar wij beperken ons bij de analyse tot drie verwante libraries.\n",
    "\n",
    "* [**MatPlotLib**](https://matplotlib.org/tutorials/introductory/sample_plots.html) (``plt``) is de basisbibliotheek die het vaakst gebruikt wordt om grafieken te tekenen in Python. Via de ``pyplot``-interface kunnen een groot aantal plots op een MATLAB-achtige manier getekend worden. Er is ook een objectgeörienteerde API beschikbaar via ``plt.subplots()``, die ``Figure`` en ``Axis`` objecten teruggeeft waarop grafieken getekend kunnen worden.\n",
    "* [**Pandas**](https://pandas.pydata.org/pandas-docs/stable/visualization.html) (``pd``) heeft geen eigen functies om plots te tekenen en gebruikt hiervoor gewoonweg MatPlotLib. De reden waarom Pandas hier apart vermeld wordt is de uitstekende API waarmee die functies gebruikt kunnen worden. Op elk ``DataFrame`` en ``Series`` object kunnen we een grote subset van MatPlotLib-functies oproepen, die in het geval van een ``DataFrame`` automatisch op elke kolom wordt toegepast.\n",
    "* [**Seaborn**](https://seaborn.pydata.org/api.html) (``sns``) is een uitbreiding op MatPlotLib die zowel functionaliteiten toevoegt als veelgebruikte MatPlotLib-functies vereenvoudigt. Seaborn-functies kunnen niet rechtstreeks worden opgeroepen op Pandas-objecten, maar kunnen er wel perfect mee overweg als argumenten.\n",
    "\n",
    "**TIP:** Bij de opdrachten zijn er vaak meerdere manieren om de gevraagde plot(s) te tekenen. Als Seaborn de methode bevat, heeft deze meestal het kleinste aantal lijnen code nodig. Deze API is wel abstracter dan bij de andere twee libraries.\n",
    "\n",
    "### Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "Creëer een plot die de spreiding van de data in alle *feature*-kolommen overzichtelijk weergeeft."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scatter Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "Teken een scatterplot die de ``color_hue`` uitzet tegenover de ``color_intensity``. Gebruik per wijnras (``type``) een andere kleur om de markers te tekenen. Wat is het verband tussen deze drie variabelen?\n",
    "\n",
    "**TIP:** Gebruik hiervoor het ``hue`` attribuut van de ``pairplot`` functie uit Seaborn, of een ``groupby`` operatie uit Pandas voor een MatPlotLib-grafiek."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "Teken een Pearson-correlatieplot van de dataset (zonder ``type``). Welke variabelen zijn het sterkst met elkaar gecorreleerd? Welke het minst? Kan je op basis van deze plot afleiden welke soort fenolen dominant zijn in wijn: flavonoïdische of niet-flavonoïdische?\n",
    "\n",
    "**Tip:** Bereken eerst de correlatie-matrix met Pandas, en teken die vervolgens met een ``heatmap`` uit Seaborn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "Plot een bivariate [*Kernel Density Estimation*](https://en.wikipedia.org/wiki/Multivariate_kernel_density_estimation) tussen ``alkalinity`` en ``proline`` voor elk ``type``.\n",
    "\n",
    "**Tip**: Gebruik hiervoor best ``kdeplot`` of de elegantere ``jointplot`` uit Seaborn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling\n",
    "\n",
    "In deze stap gaan we een aantal *machine learning* technieken bekijken waarmee we de dataset via een statistisch model met een zo laag mogelijke foutenmarge kunnen voorstellen. Deze modellen bevatten een verzameling aan *model parameters* die via een bepaald algoritme zo gefinetuned worden dat ze een combinatie van *inputs* (de features) in een *output* (de *target*) kunnen transformeren, en dat op een zo correct mogelijke manier.\n",
    "\n",
    "De algoritmes zelf worden geïnitialiseerd via een reeks *hyperparameters*, die juist gekozen moeten worden om een hoge *model accuracy* te bekomen. Het tweaken van deze parameters is vaak een tijdrovend en delicaat proces. Een té goede keuze kan immers zorgen voor een goede *accuracy* op de data waarmee de training werd uitgevoerd, maar zorgt voor een zware terugval bij testen op het voor het model onbekende data. In zo'n geval is er sprake van *overfitting*.\n",
    "\n",
    "[Scikit-learn](http://scikit-learn.org/stable/user_guide.html) (``sklearn``) is de populairste toolkit om aan *machine learning* te doen in Python. Deze library is enorm uitgebreid, en het uitproberen van alle functionaliteiten zou zeker te veel tijd kosten in dit labo. Bij de oefeningen staat er dan ook een directe verwijzing naar de juiste subpackage(s), zodat er weinig tijd wordt verloren met het doorlezen van de hele *user guide*.\n",
    "\n",
    "\n",
    "\n",
    "### Tutorial: Dimensionality Reduction\n",
    "\n",
    "Aangezien de dataset 13 verschillende features bevat, is het nogal moeilijk om deze allemaal tegelijk voor te stellen in één en dezelfde grafiek. Bij wijze van kennismaking met de Scikit-learn API gaan we de dimensies van de dataset reduceren van 13 naar 2, met een zo klein mogelijk verlies aan informatie. \n",
    "\n",
    "De techniek die we hiervoor gebruiken heet [*Principle Component Analysis*](http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html). Principieel is dit een lineaire projectie van de datapunten op een orthogonale ruimte met een lagere dimensie n. De assen van deze ruimte komen overeen met de eigenvectoren van de covariantie-matrix van de oorspronkelijke dataset die horen bij de n grootste eigenwaarden.\n",
    "\n",
    "**Let op:** Vanaf nu gebruiken we de variabele ``df_wine`` uit [1.2.4](#Wrapping-into-Pandas-ML) voor de analyse!\n",
    "\n",
    "In onderstaand voorbeeld worden zowel de pure Scikit-learn API als de wrapper-API van Pandas-ML voorgesteld. Aangezien onze data in ``DataFrame``-formaat bestaat en we de resultaten hiermee graag compatibel zouden zien, wordt al snel duidelijk dat de tweede aanpak heel wat eenvoudiger werkt. Wel is er van de eerstgenoemde API veel meer documentatie beschikbaar.\n",
    "\n",
    "We raden ten sterkste aan om voor de rest van dit labo de **Pandas-ML** methode te volgen. Deze wordt ook gebruikt in het volgende labo, en is eenvoudiger te plotten in combinatie met Seaborn.\n",
    "\n",
    "#### Pure Scikit-learn API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "locked"
    ]
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA              ## import\n",
    "\n",
    "pca = PCA(n_components=2)                          ## instantiation\n",
    "pca.fit(df_wine.data)                              ## fit the PCA model with the data (excluding the target!!!)\n",
    "df_wine_transformed = pca.transform(df_wine.data)  ## transform the data with the fitted PCA model\n",
    "                                                   ## note: the two previous steps can be combined \n",
    "                                                   ## with fit_transform\n",
    "\n",
    "df_wine_transformed[:5]                            ## results are in np.ndarray format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Pandas-ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "locked"
    ]
   },
   "outputs": [],
   "source": [
    "pca = df_wine.decomposition.PCA(n_components=2)  ## import and instantiation\n",
    "df_wine_transformed = df_wine.fit_transform(pca) ## fit and transform the data\n",
    "\n",
    "df_wine_transformed.head()                       ## results are in DataFrame format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "Teken een scatterplot voor de *components* zoals in stap [1.4.2](#Scatter-plot). \n",
    "\n",
    "**Question**: Kan op basis van deze gereduceerde features nog een duidelijk onderscheid tussen de klassen gemaakt worden?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tutorial 2: Feature Scaling\n",
    "\n",
    "Zoals beloofd in hoofdstuk [1.2.3](http://localhost:8888/notebooks/labo1.ipynb#Scaling) wordt de hele dataset eerst nog gescaled voor we er modellen mee gaan trainen. Hiervoor gebruiken we de ``MinMaxScaler`` uit [``sklearn.preprocessing``](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.preprocessing). De werking hiervan gebeurt op bijna exact dezelfde manier als in de formule uit 1.2.3. \n",
    "\n",
    "#### Train-Test-Split\n",
    "\n",
    "Zoals reeds aangehaald in de inleiding van dit hoofdstuk mogen we niet de hele dataset gebruiken om *machine learning models* te trainen wegens gevaar op *overfitting*. Via de ``train_test_split`` functie uit [``sklearn.model_selection``](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.model_selection) kunnen we een deel van onze data afzonderen en pas later opnieuw gebruiken als testset wanneer we denken dat het model af is.\n",
    "\n",
    "We splitsen de dataset op in twee delen met random geselecteerde datapunten: ``train_wine`` en ``test_wine``. De trainingset bevat 70% van de originele data, de testset de overige 30%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_wine, test_wine = df_wine.model_selection.train_test_split(test_size=0.3)\n",
    "print(len(train_wine), len(test_wine))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Scaling\n",
    "\n",
    "Nu kunnen we onze ``MinMaxScaler`` toepassen op de trainingset. De parameters die we hieruit bekomen worden vervolgens toegepast op de testset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit on train set\n",
    "scaler = train_wine.preprocessing.MinMaxScaler()\n",
    "train_wine.fit(scaler)\n",
    "\n",
    "# apply on train and test set\n",
    "train_wine = train_wine.transform(scaler)\n",
    "test_wine = test_wine.transform(scaler)\n",
    "df_wine = df_wine.transform(scaler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "Bereken de PCA uit 1.5.1 opnieuw (op ``df_wine``), en teken ook de scatterplot hiervan. Is de conclusie uit de vorige opgave nog steeds geldig?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-Test Split\n",
    "\n",
    "Zoals reeds aangehaald in de inleiding van dit hoofdstuk mogen we niet de hele dataset gebruiken om *machine learning models* te trainen wegens gevaar op *overfitting*. Via de ``train_test_split`` functie uit [``sklearn.model_selection``](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.model_selection) kunnen we een deel van onze data afzonderen en pas later opnieuw gebruiken als testset wanneer we denken dat het model af is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "Splits de dataset op in twee delen met random geselecteerde datapunten: ``train_wine`` en ``test_wine``. De trainingset moet 70% van de originele data bevatten, de testset de overige 30%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree\n",
    "\n",
    "Het eerste algoritme dat we zullen bekijken is de *decision tree* uit [``sklearn.tree``](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.tree). In zo'n model wordt stelselmatig een boomstructuur opgesteld waar in elke *node* de data opgesplitst wordt op basis van de waarde van één van de features. De trainingsmethode probeert deze *splits* zodanig te optimaliseren dat de *leafs* enkel datapunten van één bepaalde klasse bevatten.\n",
    "\n",
    "Bij deze methode is het aantal te leren parameters niet op voorhand vastgelegd, aangezien dit afhangt van de grootte en complexiteit van de dataset. Paradoxaal genoeg worden zulke algoritmes *niet-parametrisch* genoemd, ook al kunnen ze soms veel meer parameters bevatten dan *parametrische* algoritmes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "Genereer een decision tree op basis van ``train_wine`` die de data classificeert volgens wijntype. Noem het resultaat ``clf_tree``. Teken deze vervolgens met ``graphviz`` (zie User Guide)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# genereer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# teken"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "**Question:** Voer de training van de decision tree opnieuw uit, maar vervang ``train_wine`` telkens door ``train_wine.inverse_transform(scaler)`` (de originele, niet-gescalede waarden). Teken ook de boom opnieuw.\n",
    "Wat valt op? Welke van de twee bomen zou je het liefst gebruiken als classifier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine\n",
    "\n",
    "De Support Vector Machine (SVM) uit [``sklearn.svm``](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.svm) is het tweede algoritme dat we gaan bekijken. Een SVM construeert een [*hyperplane*](https://en.wikipedia.org/wiki/Hyperplane) dat de klassen van elkaar scheidt. De kracht van de SVM zit in het optimalisatiemechanisme, waarbij de *margin*, de afstand tussen het hyperplane en het dichtsbijliggende datapunt van elke klasse, gemaximaliseerd wordt. In het geval dat er meer dan twee klassen zijn, wordt er voor elke twee klassen een aparte SVM getraind (in totaal ``n * (n-1) / 2`` modellen); voor het eindresultaat worden de scores hiervan gecombineerd."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "Genereer een SVM op basis van ``train_wine`` die de data classificeert volgens wijntype. Noem het resultaat ``clf_svm``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multilayer Perceptron\n",
    "\n",
    "De laatste classifier die onderzocht wordt komt uit de familie van *neurale netwerken*. Het Multilayer Perceptron (MLP) is een netwerk dat bestaat uit een *input layer* en een *output layer*, met daartussen een aantal *hidden layers* die elk een aantal *nodes* bevatten. In elke *node* worden de waarden uit alle nodes van de vorige layer samen met een *bias* lineair gecombineerd en vervolgens door een niet-lineaire *activatiefunctie* gehaald. Door de parameters van deze lineaire combinaties te trainen op de dataset, kan dit netwerk een niet-lineaire functie vormen die de dataset-mapping van features naar target heel dicht benadert. Een nadeel van deze techniek is wel dat er relatief veel trainingsdata moet zijn om tot een acceptabel resultaat te komen.\n",
    "\n",
    "<img src=\"http://scikit-learn.org/stable/_images/multilayerperceptron_network.png\" alt=\"MLP Structure\" width=300/>\n",
    "\n",
    "De [``sklearn.neural_network``](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.neural_network) module bevat enkele klassen om met MLPs te werken. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "Creëer een multilayer perceptron op basis van ``train_wine`` die de data classificeert volgens wijntype. Noem het resultaat ``clf_mlp``. Gebruik ``'lbfgs'`` en zet het maximum aantal trainingsiteraties op 20000. Maak gebruik van de volgende structuur voor de hidden layers:\n",
    "* hidden layer 1: 20 nodes\n",
    "* hidden layer 2: 15 nodes\n",
    "* hidden layer 3: 10 nodes\n",
    "* hidden layer 4: 5 nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "**Question:** Wat is het totaal aantal *weights* of parameters dat door dit netwerk getraind moet worden (exclusief biases)? Is dit een parametrisch of niet-parametrisch model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Validation\n",
    "\n",
    "Nu we onze modellen gedefinieerd hebben, willen we uiteraard ook graag weten hoe goed ze presteren voordat we ze uiteindelijk loslaten op onze échte testdata. Er is echter een groot probleem: we hebben geen extra data meer over om deze tussentijdse test uit te voeren! We hadden deze uiteraard eerder kunnen afsplitsen van de trainingset, maar dan zou die laatste voor de algoritmes wel héél klein geworden zijn om performante modellen te genereren.\n",
    "\n",
    "De oplossing vinden we onder de vorm van *cross validation*. Bij deze techniek wordt de trainingsset niet één, maar meerdere keren opgesplitst in een (kleinere) training- en validatieset. Bij elk van deze splitsingen wordt de *accuracy score* van het model berekend, en het gemiddelde van deze scores vormt dan de *cross validation score*. Deze score blijkt in de meeste gevallen vrij representatief te zijn voor de uiteindelijke performance op de testset, en door het gebruik van de splitsingen is er geen extra data nodig om testen te doen.\n",
    "\n",
    "In [``sklearn.model_selection``](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.model_selection) vinden we de ``cross_val_score`` functie terug, samen met een aantal *splitters*. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "* Maak een ``ShuffleSplit`` object aan met 10 splits.\n",
    "* Bereken de *cross validation score* voor de drie modellen, gebruikmakend van die ``ShuffleSplit``.\n",
    "\n",
    "**Question**: Welk model presteert het best?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross validation score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction and Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Finally, the big moment has arrived!* Het is tijd om de testdata erbij te halen en te kijken hoe goed (of hoe slecht) onze modellen het doen op onbekende data. [``sklearn.metrics``](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics) bevat een groot aantal methodes om de *performance* van een model numeriek of grafisch voor te stellen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "Doe de volgende stappen voor elk van de drie modellen (hier ``clf`` genoemd):\n",
    "1. Hertrain ``clf`` op de volledige trainingset (``train_wine``).\n",
    "2. Ken ``clf`` toe aan het ``estimator`` attribuut van ``test_wine`` (enkel van toepassing bij gebruik van Pandas-ML API).\n",
    "3. Bereken de ``accuracy_score`` op ``test_wine`` met de hertrainde ``clf``.\n",
    "4. Print of teken de *confusion matrix* van ``test_wine``.\n",
    "\n",
    "**Question:** Welke classifier presteert het beste op de testset? Komt dit overeen met de bevindingen uit de cross-validatiescores? Waardoor zou een mismatch tussen *accuracy score* en *cross validation score* kunnen onstaan?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "68px",
    "width": "233px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "401.6px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 122,
   "position": {
    "height": "218px",
    "left": "189px",
    "right": "20px",
    "top": "260px",
    "width": "414px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
